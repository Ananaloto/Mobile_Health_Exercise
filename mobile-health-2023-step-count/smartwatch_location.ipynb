{"cells":[{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T17:50:11.957682Z","iopub.status.busy":"2023-03-21T17:50:11.956849Z","iopub.status.idle":"2023-03-21T17:50:11.962109Z","shell.execute_reply":"2023-03-21T17:50:11.960868Z","shell.execute_reply.started":"2023-03-21T17:50:11.957616Z"},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n","\n","# Team members (e-mail, legi):\n","# zhisun@ethz.ch, 22-958-227\n","# enjcao@ethz.ch, 22-942-700\n","# yifzhou@ethz.ch, 22-940-381"]},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-03-21T17:50:12.356641Z","iopub.status.busy":"2023-03-21T17:50:12.355451Z","iopub.status.idle":"2023-03-21T17:50:12.363393Z","shell.execute_reply":"2023-03-21T17:50:12.362041Z","shell.execute_reply.started":"2023-03-21T17:50:12.356594Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from scipy.stats import entropy\n","from scipy.signal import welch\n","from scipy.fftpack import fft\n","\n","from Lilygo.Recording import Recording, data_integrity\n","from Lilygo.Dataset import Dataset\n","\n","import joblib"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Path"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Get the path of all traces\n","dir_data = 'E:\\\\Sunzhichao\\\\ETHz\\\\2223Spring\\\\Mobile_Health\\\\data\\\\'\n","dir_traces_train = dir_data + 'train\\\\'\n","dir_traces_test = dir_data + 'test\\\\'\n","dir_labels = dir_data + 'labels\\\\'\n","dir_load = dir_data + 'Loaded_data\\\\'"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Filtering and Feature Extraction"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def get_highpass(data):\n","    filtered_data = np.zeros_like(data)  # filtered_data\n","    alpla = [1, -1.905384612118461, 0.910092542787947]\n","    beta = [0.953986986993339, -1.907503180919730, 0.953986986993339]\n","\n","    for i in range(2, len(data)):\n","        filtered_data[i] = alpla[0] * (data[i] * beta[0] + data[i-1] * beta[1] + data[i-2] * beta[2] - filtered_data[i-1] * alpla[1] - filtered_data[i-2] * alpla[2])\n","    return filtered_data\n","\n","# This funciton aims to realize a high-pass filter with cutoff frequency = 5 Hz. Because according to massive amounts of data, the general \n","# maximum frequency of human walking is about 5 Hz\n","def get_lowpass(data):\n","    filtered_data = np.zeros_like(data)  # filtered_data\n","    alpla = [1, -1.80898117793047, 0.827224480562408]\n","    beta = [0.096665967120306, -0.172688631608676, 0.095465967120306]\n","\n","    for i in range(2, len(data)):\n","        filtered_data[i] = alpla[0] * (data[i] * beta[0] + data[i-1] * beta[1] + data[i-2] * beta[2] - filtered_data[i-1] * alpla[1] - filtered_data[i-2] * alpla[2])\n","    return filtered_data\n","\n","def preprocess_and_extract_features(trace, window_size=60, sampling_rate=50):\n","    \"\"\"\n","    Preprocess the data and extract features from the 3D accelerometer, gyroscope, and magnetometer data.\n","\n","    Args:\n","    trace (Lilygo.Recording.Recording): Object containing the raw data with accelerometer data stored in lists (e.g. trace.data['ax'])\n","    window_size (int): The window size in seconds for splitting the data\n","    sampling_rate (int): The sampling rate of the data in Hz\n","\n","    Returns:\n","    pd.DataFrame: A DataFrame with the extracted features and location labels\n","    \"\"\"\n","    # Read data from trace\n","    # To-Do: filter raw data with implemented function\n","    ax = get_lowpass(get_highpass(trace.data['ax'].values))\n","    ay = get_lowpass(get_highpass(trace.data['ay'].values))\n","    az = get_lowpass(get_highpass(trace.data['az'].values))\n","    \n","    '''gx = trace.data['gx'].values\n","    gy = trace.data['gy'].values\n","    gz = trace.data['gz'].values\n","    \n","    mx = trace.data['mx'].values\n","    my = trace.data['my'].values\n","    mz = trace.data['mz'].values'''\n","    \n","    # Compute the length of each window in samples\n","    window_samples = window_size * sampling_rate\n","    \n","    # Compute the number of windows in the recording\n","    num_windows = len(ax) // window_samples\n","\n","    # Initialize lists for storing extracted features and location labels\n","    features = []\n","    loc_labels = []\n","\n","    # Helper function to compute the magnitude of a vector\n","    magnitude = lambda vec: np.sqrt(np.sum(vec**2, axis=1))\n","\n","    for i in range(num_windows):\n","       \n","        # Extract the accelerometer, gyroscope, and magnetometer data for the current window\n","        acc_data = np.array([ax[i*window_samples:(i+1)*window_samples],\n","                             ay[i*window_samples:(i+1)*window_samples],\n","                             az[i*window_samples:(i+1)*window_samples]]).T\n","        '''gyro_data = np.array([gx[i*window_samples:(i+1)*window_samples],\n","                              gy[i*window_samples:(i+1)*window_samples],\n","                              gz[i*window_samples:(i+1)*window_samples]]).T\n","        mag_data = np.array([mx[i*window_samples:(i+1)*window_samples],\n","                             my[i*window_samples:(i+1)*window_samples],\n","                             mz[i*window_samples:(i+1)*window_samples]]).T'''\n","        \n","        '''figure,ax = plt.subplots(3, 1, figsize=(10, 6))\n","        ax[0].plot(acc_data[:,0])\n","        ax[0].set_ylabel('ax')\n","        ax[1].plot(acc_data[:,1])\n","        ax[1].set_ylabel('ay')\n","        ax[2].plot(acc_data[:,2])\n","        ax[2].set_ylabel('az')'''\n","\n","        # Compute magnitudes\n","        acc_magnitude = np.sqrt(np.sum(acc_data**2, axis=1))\n","        #gyro_magnitude = magnitude(gyro_data)\n","        #mag_magnitude = magnitude(mag_data)\n","\n","        # Calculate features (according to https://www.sciencedirect.com/science/article/pii/S1574119211001222)\n","        '''ax_amp = acc_data[np.argmax(acc_data[:,0]), 0] - acc_data[np.argmin(acc_data[:,0]), 0]\n","        ay_amp = acc_data[np.argmax(acc_data[:,1]), 1] - acc_data[np.argmin(acc_data[:,1]), 1]\n","        az_amp = acc_data[np.argmax(acc_data[:,2]), 2] - acc_data[np.argmin(acc_data[:,2]), 2]'''\n","        \n","        ax_amp = abs(np.mean(acc_data[:,0]))\n","        ay_amp = abs(np.mean(acc_data[:,1]))\n","        az_amp = abs(np.mean(acc_data[:,2]))\n","        a_amp_list = [ax_amp, ay_amp, az_amp]\n","        a_amp_list.sort() # Sorting list of numbers in ascending\n","        #print('ax_amp:',ax_amp,'ay_amp:',ay_amp,'az_amp',az_amp)\n","        A = a_amp_list[2] #Feature A: the maximum amplitude among all dimensions (represents motion range for location)\n","        B = a_amp_list[2]/a_amp_list[1] # Feature B and C: ratio of the maximum amplitudes in different axes (represents DoF in movement for location)\n","        C = a_amp_list[2]/a_amp_list[0]\n","        #print('A:',A,'B:',B,'C',C)\n","\n","        # Calculate the energy and entropy of acc_mag in the frequency domain (D and F)\n","        freq, Pxx = welch(acc_magnitude, fs=sampling_rate) # use of the fast Fourier transform for the estimation of power spectra\n","        #plt.plot(freq,Pxx)\n","        \n","        D = np.max(Pxx) # Feature D: the maximum energy captured by the accelerator\n","        F = np.sum(Pxx) # Feature F: the overall energy captured by the accelerator\n","        norm_Pxx = Pxx / F # normalize the power spectrum\n","        E = entropy(norm_Pxx) # Feature E: normalized information entropy of the discrete FFT component magnitudes\n","\n","   \n","        # Append the features to the list\n","        features.append([A, B, C, D, E, F])\n","        \n","        # Calculate the timestamp for the current window as the median of the timestamps (not necessary for location)\n","        # timestamp = np.median(trace.timestamp[i*window_samples:(i+1)*window_samples]) \n","\n","        # Determine the location label for the current window based on the timestamp\n","        # loc_label = trace.labels.get('board_loc')\n","\n","        # Append the label to the labels list\n","        # loc_labels.append(loc_label)\n","    #plt.show()\n","\n","    # Create a DataFrame with the extracted features and location labels\n","    features_df = pd.DataFrame(features, columns=['A', 'B', 'C', 'D', 'E', 'F'])\n","    # features_df['loc_label'] = loc_labels\n","    #print(features_df)\n","\n","    return features_df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load training traces"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# TODO: CHANGE THIS PATH FOR KAGGLE TO LOCAL PATH\n","traceNames = [join(dir_traces_train, f) for f in listdir(dir_traces_train) if (isfile(join(dir_traces_train, f)) and f[-5:] == '.json')]\n","traceNames.sort()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Get features"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing data:  0 / 263\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9880\\3170187122.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Get features of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfeatures_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_and_extract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Prepare data for classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9880\\251480313.py\u001b[0m in \u001b[0;36mpreprocess_and_extract_features\u001b[1;34m(trace, window_size, sampling_rate)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# To-Do: filter raw data with implemented function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lowpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_highpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ax'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0may\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lowpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_highpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0maz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_lowpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_highpass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'az'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9880\\251480313.py\u001b[0m in \u001b[0;36mget_highpass\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpla\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpla\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfiltered_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpla\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfiltered_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["X = pd.DataFrame()\n","y = pd.DataFrame()\n","for i,traceName in enumerate(traceNames):\n","    if i%10 == 0:\n","        print(\"Processing data: \", i, '/', len(traceNames))\n","    trace = Recording(traceName, no_labels=False, mute=True)\n","    \n","    # Get features of data\n","    features_df = preprocess_and_extract_features(trace)\n","\n","    # Prepare data for classification\n","    X_trace = features_df.drop('loc_label', axis=1)\n","    y_trace = features_df['loc_label']\n","    X = pd.concat([X, X_trace], axis=0).reset_index(drop=True)\n","    y = pd.concat([y, y_trace], axis=0).reset_index(drop=True)\n","\n","            \n","# Normalize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# save X_scaled and y for later use\n","np.save(dir_load + 'sw_x.npy', np.array(X))\n","np.save(dir_load + 'sw_x_scaled.npy', np.array(X_scaled))\n","np.save(dir_load + 'sw_y_gt.npy', np.array(y))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train with SVM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Using features of all training traces as training set\n","X_train = X_scaled\n","y_train = y\n","#X_train, _, y_train, _ = train_test_split(X_scaled, y, test_size=0.01, random_state=42)\n","\n","# Check the number of classes in y_train\n","'''if len(set(y_train)) < 2:\n","    raise ValueError(\"The number of classes has to be greater than one; got %d class\" % len(set(y_train)))\n","'''\n","# Train the SVM classifier with RBF kernel\n","param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n","grid = GridSearchCV(SVC(kernel='rbf'), param_grid, refit=True, verbose=2)\n","grid.fit(X_train, np.ravel(y_train))\n","\n","# Save the trained SVM model\n","joblib.dump(grid, './trained_models/location_svm_model.joblib')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train with XGboost"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training XGBoost classifier for smartwatch location\n","Validation acc: 0.8482188951987609\n"]}],"source":["import xgboost as xgb\n","from xgboost import XGBClassifier\n","# Using features of all training traces as training set\n","X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Check the number of classes in y_train\n","'''if len(set(y_train)) < 2:\n","    raise ValueError(\"The number of classes has to be greater than one; got %d class\" % len(set(y_train)))\n","'''\n","# Create the XGBoost DMatrix object\n","dtrain = xgb.DMatrix(X_train, label=y_train)\n","\n","# Set the parameters for the XGBoost model\n","params = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n","\n","# Train the model\n","xgb_model = xgb.train(params, dtrain)\n","print(\"Training XGBoost classifier for smartwatch location\")\n","\n","# Create the XGBoost DMatrix object for the test data\n","dval = xgb.DMatrix(X_val)\n","\n","# Make predictions on the test set and evaluate the model\n","y_pred = xgb_model.predict(dval)\n","accuracy = accuracy_score(y_pred, y_val)\n","# Evaluate the model on the testing data\n","print(\"Validation acc:\", accuracy)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Predict on testing traces with trained model and Evaluation predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the trained model for prediction\n","loaded_model = joblib.load('./trained_models/location_svm_model.joblib')\n","\n","# Load testing data\n","# TODO: CHANGE THIS PATH FOR KAGGLE TO LOCAL PATH\n","path_testing = '/kaggle/input/mobile-health-2023-path-detection/data/test'\n","traceNames_test = os.listdir(path_testing)\n","\n","# labels and final prediction for the whole traces\n","y_labels = []\n","y_finals = []\n","for traceName in traceNames_test[0:3]:\n","    if traceName[-5:] == '.json':\n","        trace = Recording(path_testing + '/'+ traceName, no_labels=True, mute=True)\n","        \n","        # Get features of data\n","        features_df = preprocess_and_extract_features(trace)\n","\n","        # Prepare data for classification\n","        X_test = scaler.fit_transform(features_df)\n","\n","        # Predict the location with loaded model\n","        y_pred = loaded_model.predict(X_test)\n","        y_pred = np.squeeze(y_pred)\n","        y_final = np.argmax(np.bincount(y_pred.astype(int)))\n","        \n","        y_finals.append(y_final)\n","\n","y_finals = np.array(y_finals)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["number of traces in training for loaction 0:  84 , loaction 1:  82 , loaction 2:  97\n"]}],"source":["y_gt = np.load(dir_load + 'train_loaction_label.npy')\n","# check training data balance\n","loaction_1 = np.count_nonzero(y_gt == 1)\n","loaction_2 = np.count_nonzero(y_gt == 2)\n","location_0 = np.shape(y_gt)[0] - loaction_1 - loaction_2\n","print(\"number of traces in training for loaction 0: \", location_0, \", loaction 1: \", loaction_1, \", loaction 2: \", loaction_2)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["predicted window label:  [0. 0. 2. 0. 1. 0. 0. 0. 0. 2. 2. 1. 2. 2. 2. 2. 0. 0. 0. 0. 0. 0. 0. 2.\n"," 2. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n","predicted trace label:  0  ground truth:  2\n","predicted window label:  [2. 0. 1. 2. 2. 1. 2. 1. 2. 2. 2. 1. 1. 1. 1. 2. 1. 1. 0. 0. 0. 0. 2. 2.\n"," 1. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [1. 1. 0. 2. 1. 0. 0. 2. 0. 0. 1. 0. 2. 2. 2. 0. 0. 0. 0. 1. 1. 2. 2. 2.\n"," 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 0. 2. 2. 0. 2. 2. 0. 0. 2. 2. 2. 1. 2. 1.\n"," 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 0.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [0. 0. 2. 0. 2. 2. 0. 1. 1. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1.\n"," 2. 1. 0. 1. 1. 2. 2. 0.]\n","predicted trace label:  2  ground truth:  1\n","predicted window label:  [2. 1. 2. 0. 0. 0. 0. 2. 2. 2. 0. 2. 0. 2. 0. 1. 0. 1. 2. 1. 2. 0. 1. 0.\n"," 2. 0. 0. 2. 0. 0. 0. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [0. 2. 0. 2. 1. 2. 2. 2. 2. 2. 0. 0. 0. 2. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0.\n"," 2. 2. 2. 2. 2. 1. 2. 1. 2. 2. 2. 2. 2. 1. 2.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [0. 2. 1. 0. 1. 2. 2. 2. 2. 2. 2. 0. 2. 1. 0. 1. 1. 0. 1. 0. 1. 2. 2. 0.\n"," 1. 0. 2. 2. 2. 2. 2. 2. 0. 0. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [0. 2. 2. 2. 1. 2. 0. 2. 2. 0. 0.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 2. 0. 2. 0. 0. 2. 0. 0. 2. 0. 0. 2. 0.\n"," 1. 2. 0. 1. 2. 0. 2. 0. 2. 0. 2. 0. 1. 1. 2. 1. 2. 2. 1. 1. 2. 1. 2. 2.\n"," 2. 2.]\n","predicted trace label:  0  ground truth:  2\n","predicted window label:  [2. 1. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 0. 2. 1. 1. 0. 2. 2. 2. 2.\n"," 2. 2. 0. 2. 2. 2. 1. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  1\n","predicted window label:  [1. 1. 1. 0. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 0. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 2. 0. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [2. 2. 0. 2. 2. 0. 2. 2. 2. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 2. 0. 0. 0.\n"," 0. 2. 0. 0. 1. 0. 0. 0. 0. 2. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2.]\n","predicted trace label:  0  ground truth:  1\n","predicted window label:  [0. 0. 0. 0. 2. 2. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 2. 2. 1. 1. 1. 1. 0. 0.\n"," 0. 0. 0. 2. 0. 2. 2. 0. 1. 1. 1. 1. 1. 1. 1.]\n","predicted trace label:  0  ground truth:  2\n","predicted window label:  [2. 2. 1. 0. 1. 0. 2. 0. 2. 2. 2. 2. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n"," 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","predicted trace label:  0  ground truth:  2\n","predicted window label:  [1. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 1. 1. 0. 2. 1. 1. 2. 2.\n"," 2. 0. 2. 2. 2. 2. 2. 0. 0. 2. 1. 2. 2. 2. 2. 2. 2. 1. 0. 0. 0. 1. 1.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n"," 1.]\n","predicted trace label:  2  ground truth:  1\n","predicted window label:  [1. 1. 0. 0. 1. 2. 1. 2. 0. 0. 1. 0. 2. 2. 0. 0. 2. 1. 2. 2. 0. 2. 0. 1.\n"," 2. 2. 2. 1. 1. 0. 0. 2. 0. 1. 2. 2. 2. 1. 2. 2.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [1. 0. 1. 0. 1. 1. 2. 0. 2. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2.\n"," 2. 2. 1. 0. 2.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 2. 1. 1. 2. 1. 2. 0. 0. 2. 2. 2. 2. 0. 0.\n"," 0. 2. 2. 2. 2. 2. 1. 1. 1. 2. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  0\n","predicted window label:  [0. 2. 0. 2. 2. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 2. 1. 2. 2. 1.\n"," 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [0. 0. 0. 2. 0. 2. 1. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 2. 2. 0. 2. 2.]\n","predicted trace label:  2  ground truth:  1\n","predicted window label:  [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0.\n"," 2. 2. 0. 2. 2. 2. 2. 2. 0. 0. 0.]\n","predicted trace label:  2  ground truth:  1\n","predicted window label:  [1. 0. 1. 1. 1. 1. 1. 0. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 1.\n"," 2. 2. 0. 2. 2. 2. 0. 2. 0. 0. 0. 0. 0. 0.]\n","predicted trace label:  2  ground truth:  1\n","predicted window label:  [2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 0. 1. 1. 1. 1. 2. 1. 2. 2. 2. 2.\n"," 2. 0. 2. 1. 1. 2. 2. 1. 0. 2. 0. 0. 0. 0. 0.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [0. 0. 2. 0. 1. 1. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2. 0. 1. 0. 0. 0. 0. 1.\n"," 2. 2. 2. 1. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n"," 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n","predicted trace label:  1  ground truth:  2\n","predicted window label:  [0. 2. 0. 1. 0. 2. 0. 0. 0. 1. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 0.\n"," 1. 0. 1. 0. 0. 0. 0. 2. 2. 2.]\n","predicted trace label:  0  ground truth:  1\n","predicted window label:  [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 2. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n"," 1. 2. 0. 0. 0. 2. 0. 0. 1. 1. 1.]\n","predicted trace label:  0  ground truth:  1\n","predicted window label:  [0. 2. 2. 0. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 2. 0. 2. 0. 0.\n"," 0. 1. 1. 2. 0. 2. 1. 0. 0. 0. 2.]\n","predicted trace label:  0  ground truth:  0\n","predicted window label:  [0. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 1. 0. 0. 0. 2. 0. 2. 2. 0. 1.\n"," 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0. 0. 0.]\n","predicted trace label:  0  ground truth:  0\n","predicted window label:  [1. 1. 1. 2. 2. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 2. 0. 0. 0. 0. 0. 1. 0.]\n","predicted trace label:  0  ground truth:  2\n","predicted window label:  [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 2. 1. 1. 1. 1. 2. 1. 2. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 1. 1. 0. 1. 2. 2. 0. 0. 0. 0. 0.]\n","predicted trace label:  0  ground truth:  0\n","predicted window label:  [2. 1. 1. 0. 1. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","predicted trace label:  0  ground truth:  0\n","predicted window label:  [1. 2. 2. 2. 1. 2. 2. 0. 1. 1. 1. 1. 1. 0. 1. 1. 2. 2. 0. 2. 0. 1. 0. 2.\n"," 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [2. 2. 0. 2. 2. 2. 2. 2. 1. 0. 0. 2. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 2.\n"," 0. 0. 0. 2. 2. 1. 0. 0. 0. 2. 2. 2.]\n","predicted trace label:  0  ground truth:  1\n","predicted window label:  [0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n"," 2. 2. 2. 2. 2. 1. 1. 2. 0. 2. 2. 2. 2. 2. 2. 0. 2.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [1. 1. 0. 0. 2. 0. 2. 2. 2. 0. 0. 0. 1. 2. 1.]\n","predicted trace label:  0  ground truth:  1\n","predicted window label:  [1. 1. 2. 2. 2. 2. 2. 2. 2. 0. 1. 0. 0. 0. 0. 2. 2. 2. 2. 0. 0. 0. 0. 0.\n"," 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 0.]\n","predicted trace label:  2  ground truth:  2\n","predicted window label:  [0. 2. 2. 2. 2. 1. 1. 2. 0. 0. 1. 0. 1. 0. 0. 0. 2. 0. 0. 2. 0. 0. 2. 2.\n"," 1. 1. 1. 2. 2.]\n","predicted trace label:  0  ground truth:  1\n","predicted window label:  [2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 2. 0. 0. 1. 0. 1. 1. 2. 0. 1.\n"," 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 2. 0. 2. 2. 2.]\n","predicted trace label:  2  ground truth:  0\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9880\\153396308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0my_finals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraceNames_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRecording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraceName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Get features of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32me:\\Github\\Mobile_Health_Exercise\\mobile-health-2023-step-count\\Lilygo\\Recording.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, no_labels, mute)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;31m# Will hold a dictionary directly read from the JSON file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmute\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAllData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32me:\\Github\\Mobile_Health_Exercise\\mobile-health-2023-step-count\\Lilygo\\Recording.py\u001b[0m in \u001b[0;36mreadFile\u001b[1;34m(self, filename, no_labels, mute)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfile_str\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'['\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfile_str\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m']'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mfile_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m']'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\szzcc\\.conda\\envs\\mhealth23\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\szzcc\\.conda\\envs\\mhealth23\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\szzcc\\.conda\\envs\\mhealth23\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# predict using XGBoost\n","traceNames_test = [join(dir_traces_test, f) for f in listdir(dir_traces_test) if (isfile(join(dir_traces_test, f)) and f[-5:] == '.json')]\n","traceNames_test.sort()\n","# labels and final prediction for the whole traces\n","y_labels = []\n","y_finals = []\n","for i, traceName in enumerate(traceNames_test):\n","    trace = Recording(traceName, no_labels=True, mute=True)\n","    \n","    # Get features of data\n","    features_df = preprocess_and_extract_features(trace)\n","\n","    # Prepare data for classification\n","    X_test = scaler.fit_transform(features_df)\n","    # Create the XGBoost DMatrix object for the test data\n","    dtest = xgb.DMatrix(X_test)\n","    \n","    # Make predictions on the test set and evaluate the model\n","    y_pred = xgb_model.predict(dtest)\n","    print(\"predicted window label: \", y_pred)\n","    y_pred = np.squeeze(y_pred)\n","    y_final = np.argmax(np.bincount(y_pred.astype(int)))\n","    print(\"predicted trace label: \", y_final, \" ground truth: \", y_gt[i])\n","    y_finals.append(y_final)\n","\n","y_finals = np.array(y_finals)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
