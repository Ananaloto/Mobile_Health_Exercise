{"cells":[{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-03-21T17:50:11.957682Z","iopub.status.busy":"2023-03-21T17:50:11.956849Z","iopub.status.idle":"2023-03-21T17:50:11.962109Z","shell.execute_reply":"2023-03-21T17:50:11.960868Z","shell.execute_reply.started":"2023-03-21T17:50:11.957616Z"},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["# This is the template for the submission. If you want, you can develop your algorithm in a regular Python script and copy the code here for submission.\n","\n","# Team members (e-mail, legi):\n","# zhisun@ethz.ch, 22-958-227\n","# enjcao@ethz.ch, 22-942-700\n","# yifzhou@ethz.ch, 22-940-381"]},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-03-21T17:50:12.356641Z","iopub.status.busy":"2023-03-21T17:50:12.355451Z","iopub.status.idle":"2023-03-21T17:50:12.363393Z","shell.execute_reply":"2023-03-21T17:50:12.362041Z","shell.execute_reply.started":"2023-03-21T17:50:12.356594Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import math\n","from Lilygo.Recording import Recording\n","from Lilygo.Dataset import Dataset\n","from os import listdir\n","from os.path import isfile, join\n","from math import sqrt\n","import numpy as np\n","from scipy import signal\n","import matplotlib.pyplot as plt\n","from scipy.interpolate import interp1d\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.svm import SVC\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Get the path of all traces\n","dir_data = 'E:\\\\Sunzhichao\\\\ETHz\\\\2223Spring\\\\Mobile_Health\\\\data\\\\'\n","dir_traces = dir_data + 'train\\\\'\n","dir_labels = dir_data + 'labels\\\\'\n","dir_loaded = dir_data + 'Loaded_data\\\\'\n","dir_models = dir_data + 'models\\\\'\n","# recorded\n","dir_recorded = 'data/recorded'"]},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"execution":{"iopub.execute_input":"2023-03-21T18:41:54.738799Z","iopub.status.busy":"2023-03-21T18:41:54.738348Z","iopub.status.idle":"2023-03-21T18:41:54.782198Z","shell.execute_reply":"2023-03-21T18:41:54.781291Z","shell.execute_reply.started":"2023-03-21T18:41:54.738760Z"},"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"trusted":true},"outputs":[],"source":["filenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f)) and f[-5:] == '.json']\n","filenames.sort()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# load magnetometer data and path index ground truth\n","data_magnet = np.load(dir_loaded + \"train_data_magnet.npy\", allow_pickle=True).item()\n","data_acc = np.load(dir_loaded + \"train_data_acc_resample.npy\", allow_pickle=True).item()\n","path_indexs = np.load(dir_loaded + \"train_path_label_corrected.npy\")\n","data_len = np.shape(data_magnet['magn'])[1]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# compute the change of data\n","def compute_rate_of_change(data):\n","    rate_of_change = np.diff(data)\n","    return rate_of_change"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Following blocks are CNN model for magnatometer data only(magnitute or x, y, z data)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# Define the CNN model for x, y, z data\n","class CNN1D_3(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN1D_3, self).__init__()\n","        self.conv1 = nn.Conv1d(3, 32, kernel_size=5)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool1d(2)\n","        self.conv2 = nn.Conv1d(32, 64, kernel_size=5)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool1d(2)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(64 * 247, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool1(self.relu1(self.conv1(x)))\n","        x = self.pool2(self.relu2(self.conv2(x)))\n","        x = self.flatten(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Define the CNN model for magnitute data\n","class CNN1D(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CNN1D, self).__init__()\n","        self.conv1 = nn.Conv1d(1, 32, kernel_size=5)\n","        self.relu1 = nn.ReLU()\n","        self.maxpool1 = nn.MaxPool1d(kernel_size=2)\n","        self.conv2 = nn.Conv1d(32, 64, kernel_size=5)\n","        self.relu2 = nn.ReLU()\n","        self.maxpool2 = nn.MaxPool1d(kernel_size=2)\n","        self.dropout = nn.Dropout(p=0.5)  # Add dropout layer with 50% dropout probability\n","        self.fc1 = nn.Linear(64 * 247, 255)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(255, num_classes)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.maxpool1(x)\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.maxpool2(x)\n","        x = self.dropout(x)  # Apply dropout\n","        x = x.view(x.size(0), -1)\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Define a custom dataset class\n","class PathDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Define the L1 regularization term\n","def l1_regularization(model, lambda_l1):\n","    l1_loss = torch.tensor(0., requires_grad=True)\n","    for param in model.parameters():\n","        l1_loss = torch.norm(param, 1) + l1_loss\n","    return lambda_l1 * l1_loss"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'PathDataset' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\1620064088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create dataset and dataloader objects for training and validation sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPathDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPathDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'PathDataset' is not defined"]}],"source":["# Convert resampled data and labels to tensors\n","X = torch.tensor(np.expand_dims(data_magnet['magn'], axis=-1), dtype=torch.float32)\n","# all_axes_data = np.stack((data_magnet['x'], data_magnet['y'], data_magnet['z']), axis=-1)\n","# X = torch.tensor(all_axes_data, dtype=torch.float32)\n","y = torch.tensor(path_indexs, dtype=torch.long)\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create dataset and dataloader objects for training and validation sets\n","train_dataset = PathDataset(X_train, y_train)\n","val_dataset = PathDataset(X_val, y_val)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize the CNN model and other training components\n","num_classes = 5\n","model = CNN1D(num_classes).to(device)\n","# Set the L1 regularization strength (lambda_l1)\n","lambda_l1 = 1e-5\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.00001)\n","# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","\n","# Training parameters\n","num_epochs = 300\n","best_val_accuracy = 0\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    model.train()\n","    correct_train = 0\n","    total_train = 0\n","\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        inputs = inputs.permute(0, 2, 1)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        # Compute the number of correct predictions and the total number of predictions\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += targets.size(0)\n","        correct_train += (predicted == targets).sum().item()\n","        # Compute the total loss, including the L1 regularization term\n","        loss = criterion(outputs, targets) + l1_regularization(model, lambda_l1)\n","        \n","        \n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * inputs.size(0)\n","\n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_accuracy = 100 * correct_train / total_train\n","    \n","    # Validation loop\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            \n","            inputs = inputs.permute(0, 2, 1)\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","    val_accuracy = correct / total\n","\n","    # Save the model with the best validation accuracy\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        torch.save(model.state_dict(), dir_models+\"path_index_cnn_model.pth\")\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f},Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["lr=1e-05, batch_size=16, weight_decay=0, cross_val_accuracy=0.5185185185185185\n","lr=1e-05, batch_size=16, weight_decay=0.0001, cross_val_accuracy=0.5074074074074074\n","lr=1e-05, batch_size=16, weight_decay=1e-05, cross_val_accuracy=0.5148148148148148\n","lr=1e-05, batch_size=32, weight_decay=0, cross_val_accuracy=0.47407407407407404\n","lr=1e-05, batch_size=32, weight_decay=0.0001, cross_val_accuracy=0.4888888888888888\n","lr=1e-05, batch_size=32, weight_decay=1e-05, cross_val_accuracy=0.5111111111111111\n","lr=1e-05, batch_size=64, weight_decay=0, cross_val_accuracy=0.49629629629629635\n","lr=1e-05, batch_size=64, weight_decay=0.0001, cross_val_accuracy=0.4814814814814815\n","lr=1e-05, batch_size=64, weight_decay=1e-05, cross_val_accuracy=0.4814814814814815\n","lr=5e-06, batch_size=16, weight_decay=0, cross_val_accuracy=0.5\n","lr=5e-06, batch_size=16, weight_decay=0.0001, cross_val_accuracy=0.5074074074074074\n","lr=5e-06, batch_size=16, weight_decay=1e-05, cross_val_accuracy=0.5185185185185185\n","lr=5e-06, batch_size=32, weight_decay=0, cross_val_accuracy=0.47407407407407415\n","lr=5e-06, batch_size=32, weight_decay=0.0001, cross_val_accuracy=0.4851851851851852\n","lr=5e-06, batch_size=32, weight_decay=1e-05, cross_val_accuracy=0.49629629629629635\n","lr=5e-06, batch_size=64, weight_decay=0, cross_val_accuracy=0.4296296296296296\n","lr=5e-06, batch_size=64, weight_decay=0.0001, cross_val_accuracy=0.47777777777777775\n","lr=5e-06, batch_size=64, weight_decay=1e-05, cross_val_accuracy=0.4666666666666667\n","lr=1e-06, batch_size=16, weight_decay=0, cross_val_accuracy=0.38888888888888895\n","lr=1e-06, batch_size=16, weight_decay=0.0001, cross_val_accuracy=0.4333333333333333\n","lr=1e-06, batch_size=16, weight_decay=1e-05, cross_val_accuracy=0.44074074074074077\n","lr=1e-06, batch_size=32, weight_decay=0, cross_val_accuracy=0.3592592592592592\n","lr=1e-06, batch_size=32, weight_decay=0.0001, cross_val_accuracy=0.3518518518518518\n","lr=1e-06, batch_size=32, weight_decay=1e-05, cross_val_accuracy=0.37037037037037035\n","lr=1e-06, batch_size=64, weight_decay=0, cross_val_accuracy=0.3407407407407407\n","lr=1e-06, batch_size=64, weight_decay=0.0001, cross_val_accuracy=0.32592592592592595\n","lr=1e-06, batch_size=64, weight_decay=1e-05, cross_val_accuracy=0.3\n","Best hyperparameters: {'lr': 1e-05, 'batch_size': 16, 'weight_decay': 0}\n","Best cross-validation accuracy: 0.5185185185185185\n"]}],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import KFold\n","\n","\n","# Convert resampled data and labels to tensors\n","data = np.transpose(np.expand_dims(data_magnet['magn'], axis=-1), (0, 2, 1))\n","data = torch.tensor(data, dtype=torch.float32)\n","# all_axes_data = np.stack((data_magnet['x'], data_magnet['y'], data_magnet['z']), axis=-1)\n","# X = torch.tensor(all_axes_data, dtype=torch.float32)\n","labels = torch.tensor(path_indexs, dtype=torch.long)\n","\n","# Define hyperparameters for grid search\n","learning_rates = [0.00001, 0.000005, 0.000001]\n","num_epochs = 100\n","batch_sizes = [16, 32, 64]\n","weight_decays = [0, 1e-4, 1e-5]\n","\n","# Define the number of folds for cross-validation\n","num_folds = 5\n","kf = KFold(n_splits=num_folds, shuffle=True)\n","\n","# Function to train and evaluate the model\n","def train_and_evaluate(model, train_loader, val_loader, optimizer, criterion):\n","    best_val_accuracy = 0\n","    for epoch in range(num_epochs):\n","        model.train()\n","        for inputs, targets in train_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, targets in val_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)\n","                outputs = model(inputs)\n","                _, predicted = torch.max(outputs, 1)\n","                total += targets.size(0)\n","                correct += (predicted == targets).sum().item()\n","        val_accuracy = correct / total\n","        if val_accuracy > best_val_accuracy:\n","            best_val_accuracy = val_accuracy\n","        # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f},Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n","    return best_val_accuracy\n","\n","# Perform grid search and k-fold cross-validation\n","best_hyperparams = None\n","best_cross_val_accuracy = 0\n","for lr in learning_rates:\n","    for batch_size in batch_sizes:\n","        for weight_decay in weight_decays:\n","            fold_accuracies = []\n","            for train_indices, val_indices in kf.split(data):\n","                # Create the model\n","                num_classes = 5\n","                model = CNN1D(num_classes).to(device)\n","                \n","                # Create the optimizer with the current hyperparameters\n","                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","                \n","                # Define the loss function (criterion)\n","                criterion = nn.CrossEntropyLoss()\n","\n","                # Prepare the data loaders for the current fold\n","                train_dataset = PathDataset(data[train_indices], labels[train_indices])\n","                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","                val_dataset = PathDataset(data[val_indices], labels[val_indices])\n","                val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","                # Set device\n","                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","                \n","                \n","                # Train and evaluate the model with the current fold and hyperparameters\n","                fold_accuracy = train_and_evaluate(model, train_loader, val_loader, optimizer, criterion)\n","                fold_accuracies.append(fold_accuracy)\n","\n","            # Calculate the average accuracy across all folds for the current hyperparameters\n","            cross_val_accuracy = np.mean(fold_accuracies)\n","            print(f'lr={lr}, batch_size={batch_size}, weight_decay={weight_decay}, cross_val_accuracy={cross_val_accuracy}')\n","\n","            # Update the best hyperparameters if the current cross_val_accuracy is higher\n","            if cross_val_accuracy > best_cross_val_accuracy:\n","                best_cross_val_accuracy = cross_val_accuracy\n","                best_hyperparams = {'lr': lr, 'batch_size': batch_size, 'weight_decay': weight_decay}\n","\n","print(f'Best hyperparameters: {best_hyperparams}')\n","print(f'Best cross-validation accuracy: {best_cross_val_accuracy}')\n","               \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Following blocks are for MLP model for accelerometer data and magnatometer data"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["# MLP for accelerometer and magnetometer data\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","\n","# Define the MLP model\n","class MLP(nn.Module):\n","    def __init__(self, input_length, num_sensors, num_classes):\n","        super(MLP, self).__init__()\n","        self.input_length = input_length\n","        self.num_sensors = num_sensors\n","        # self.fc1 = nn.Linear(input_length * num_sensors, hidden_size)\n","        # self.relu = nn.ReLU()\n","        # self.fc2 = nn.Linear(hidden_size, num_classes)\n","        # self.sigmoid = torch.nn.Sigmoid()\n","\n","        self.fc = torch.nn.Sequential(\n","        torch.nn.Linear(in_features=input_length * num_sensors, out_features=2000),\n","        # torch.nn.ReLU(),\n","        # torch.nn.Dropout(0.5),\n","        # torch.nn.Linear(in_features=2000, out_features=1000),\n","        torch.nn.ReLU(),\n","        torch.nn.Dropout(0.5),\n","        torch.nn.Linear(in_features=2000, out_features=num_classes),\n","        torch.nn.Sigmoid())\n","\n","    def forward(self, x):\n","        x = x.view(-1, self.input_length * self.num_sensors)\n","        # x = self.fc1(x)\n","        # x = self.relu(x)\n","        # x = self.fc2(x)\n","        # x = self.sigmoid(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/500, Loss: 1.6910,Train Accuracy: 18.06%, Validation Accuracy: 27.78%\n","Epoch 2/500, Loss: 1.6745,Train Accuracy: 23.15%, Validation Accuracy: 25.93%\n","Epoch 3/500, Loss: 1.6940,Train Accuracy: 18.06%, Validation Accuracy: 25.93%\n","Epoch 4/500, Loss: 1.7128,Train Accuracy: 16.67%, Validation Accuracy: 25.93%\n","Epoch 5/500, Loss: 1.6481,Train Accuracy: 24.07%, Validation Accuracy: 25.93%\n","Epoch 6/500, Loss: 1.6587,Train Accuracy: 18.06%, Validation Accuracy: 24.07%\n","Epoch 7/500, Loss: 1.6843,Train Accuracy: 16.67%, Validation Accuracy: 24.07%\n","Epoch 8/500, Loss: 1.6420,Train Accuracy: 23.15%, Validation Accuracy: 24.07%\n","Epoch 9/500, Loss: 1.6638,Train Accuracy: 23.15%, Validation Accuracy: 24.07%\n","Epoch 10/500, Loss: 1.6371,Train Accuracy: 22.69%, Validation Accuracy: 25.93%\n","Epoch 11/500, Loss: 1.6741,Train Accuracy: 20.37%, Validation Accuracy: 25.93%\n","Epoch 12/500, Loss: 1.6448,Train Accuracy: 24.07%, Validation Accuracy: 27.78%\n","Epoch 13/500, Loss: 1.6593,Train Accuracy: 24.54%, Validation Accuracy: 24.07%\n","Epoch 14/500, Loss: 1.5990,Train Accuracy: 24.54%, Validation Accuracy: 24.07%\n","Epoch 15/500, Loss: 1.6447,Train Accuracy: 20.83%, Validation Accuracy: 20.37%\n","Epoch 16/500, Loss: 1.6185,Train Accuracy: 28.24%, Validation Accuracy: 20.37%\n","Epoch 17/500, Loss: 1.6204,Train Accuracy: 23.15%, Validation Accuracy: 22.22%\n","Epoch 18/500, Loss: 1.6351,Train Accuracy: 18.98%, Validation Accuracy: 24.07%\n","Epoch 19/500, Loss: 1.5860,Train Accuracy: 29.63%, Validation Accuracy: 24.07%\n","Epoch 20/500, Loss: 1.6662,Train Accuracy: 16.67%, Validation Accuracy: 22.22%\n","Epoch 21/500, Loss: 1.6110,Train Accuracy: 27.31%, Validation Accuracy: 22.22%\n","Epoch 22/500, Loss: 1.6007,Train Accuracy: 31.02%, Validation Accuracy: 24.07%\n","Epoch 23/500, Loss: 1.5839,Train Accuracy: 27.78%, Validation Accuracy: 25.93%\n","Epoch 24/500, Loss: 1.6129,Train Accuracy: 25.00%, Validation Accuracy: 24.07%\n","Epoch 25/500, Loss: 1.5699,Train Accuracy: 33.33%, Validation Accuracy: 24.07%\n","Epoch 26/500, Loss: 1.6314,Train Accuracy: 21.76%, Validation Accuracy: 24.07%\n","Epoch 27/500, Loss: 1.5771,Train Accuracy: 30.56%, Validation Accuracy: 24.07%\n","Epoch 28/500, Loss: 1.6036,Train Accuracy: 29.63%, Validation Accuracy: 24.07%\n","Epoch 29/500, Loss: 1.5903,Train Accuracy: 27.78%, Validation Accuracy: 24.07%\n","Epoch 30/500, Loss: 1.6075,Train Accuracy: 24.07%, Validation Accuracy: 24.07%\n","Epoch 31/500, Loss: 1.5861,Train Accuracy: 24.07%, Validation Accuracy: 24.07%\n","Epoch 32/500, Loss: 1.5760,Train Accuracy: 28.70%, Validation Accuracy: 24.07%\n","Epoch 33/500, Loss: 1.5912,Train Accuracy: 26.85%, Validation Accuracy: 24.07%\n","Epoch 34/500, Loss: 1.5991,Train Accuracy: 29.17%, Validation Accuracy: 24.07%\n","Epoch 35/500, Loss: 1.5983,Train Accuracy: 25.46%, Validation Accuracy: 24.07%\n","Epoch 36/500, Loss: 1.5715,Train Accuracy: 31.02%, Validation Accuracy: 25.93%\n","Epoch 37/500, Loss: 1.5859,Train Accuracy: 27.78%, Validation Accuracy: 25.93%\n","Epoch 38/500, Loss: 1.5547,Train Accuracy: 31.48%, Validation Accuracy: 25.93%\n","Epoch 39/500, Loss: 1.5447,Train Accuracy: 37.04%, Validation Accuracy: 25.93%\n","Epoch 40/500, Loss: 1.5618,Train Accuracy: 27.78%, Validation Accuracy: 25.93%\n","Epoch 41/500, Loss: 1.5587,Train Accuracy: 33.80%, Validation Accuracy: 25.93%\n","Epoch 42/500, Loss: 1.5741,Train Accuracy: 31.02%, Validation Accuracy: 25.93%\n","Epoch 43/500, Loss: 1.5847,Train Accuracy: 29.17%, Validation Accuracy: 27.78%\n","Epoch 44/500, Loss: 1.5496,Train Accuracy: 28.70%, Validation Accuracy: 29.63%\n","Epoch 45/500, Loss: 1.5822,Train Accuracy: 24.07%, Validation Accuracy: 29.63%\n","Epoch 46/500, Loss: 1.5478,Train Accuracy: 32.41%, Validation Accuracy: 31.48%\n","Epoch 47/500, Loss: 1.5633,Train Accuracy: 33.80%, Validation Accuracy: 27.78%\n","Epoch 48/500, Loss: 1.5462,Train Accuracy: 30.56%, Validation Accuracy: 27.78%\n","Epoch 49/500, Loss: 1.5534,Train Accuracy: 33.33%, Validation Accuracy: 27.78%\n","Epoch 50/500, Loss: 1.5639,Train Accuracy: 31.94%, Validation Accuracy: 27.78%\n","Epoch 51/500, Loss: 1.5466,Train Accuracy: 34.26%, Validation Accuracy: 25.93%\n","Epoch 52/500, Loss: 1.6000,Train Accuracy: 25.46%, Validation Accuracy: 27.78%\n","Epoch 53/500, Loss: 1.5635,Train Accuracy: 34.72%, Validation Accuracy: 27.78%\n","Epoch 54/500, Loss: 1.5518,Train Accuracy: 37.50%, Validation Accuracy: 25.93%\n","Epoch 55/500, Loss: 1.5376,Train Accuracy: 31.02%, Validation Accuracy: 27.78%\n","Epoch 56/500, Loss: 1.5645,Train Accuracy: 34.26%, Validation Accuracy: 24.07%\n","Epoch 57/500, Loss: 1.5794,Train Accuracy: 31.02%, Validation Accuracy: 22.22%\n","Epoch 58/500, Loss: 1.5899,Train Accuracy: 28.70%, Validation Accuracy: 25.93%\n","Epoch 59/500, Loss: 1.5402,Train Accuracy: 29.63%, Validation Accuracy: 25.93%\n","Epoch 60/500, Loss: 1.5464,Train Accuracy: 32.87%, Validation Accuracy: 27.78%\n","Epoch 61/500, Loss: 1.5324,Train Accuracy: 33.80%, Validation Accuracy: 29.63%\n","Epoch 62/500, Loss: 1.5630,Train Accuracy: 29.17%, Validation Accuracy: 27.78%\n","Epoch 63/500, Loss: 1.5486,Train Accuracy: 29.63%, Validation Accuracy: 27.78%\n","Epoch 64/500, Loss: 1.5377,Train Accuracy: 37.04%, Validation Accuracy: 27.78%\n","Epoch 65/500, Loss: 1.5434,Train Accuracy: 35.65%, Validation Accuracy: 27.78%\n","Epoch 66/500, Loss: 1.5384,Train Accuracy: 31.94%, Validation Accuracy: 27.78%\n","Epoch 67/500, Loss: 1.5225,Train Accuracy: 36.11%, Validation Accuracy: 27.78%\n","Epoch 68/500, Loss: 1.5394,Train Accuracy: 30.56%, Validation Accuracy: 27.78%\n","Epoch 69/500, Loss: 1.5139,Train Accuracy: 33.80%, Validation Accuracy: 27.78%\n","Epoch 70/500, Loss: 1.5498,Train Accuracy: 31.02%, Validation Accuracy: 25.93%\n","Epoch 71/500, Loss: 1.5367,Train Accuracy: 33.33%, Validation Accuracy: 25.93%\n","Epoch 72/500, Loss: 1.4718,Train Accuracy: 41.20%, Validation Accuracy: 25.93%\n","Epoch 73/500, Loss: 1.5365,Train Accuracy: 31.94%, Validation Accuracy: 25.93%\n","Epoch 74/500, Loss: 1.5333,Train Accuracy: 36.57%, Validation Accuracy: 25.93%\n","Epoch 75/500, Loss: 1.5062,Train Accuracy: 37.04%, Validation Accuracy: 25.93%\n","Epoch 76/500, Loss: 1.5255,Train Accuracy: 33.33%, Validation Accuracy: 25.93%\n","Epoch 77/500, Loss: 1.4938,Train Accuracy: 40.28%, Validation Accuracy: 24.07%\n","Epoch 78/500, Loss: 1.4990,Train Accuracy: 41.20%, Validation Accuracy: 24.07%\n","Epoch 79/500, Loss: 1.5006,Train Accuracy: 42.13%, Validation Accuracy: 24.07%\n","Epoch 80/500, Loss: 1.5261,Train Accuracy: 35.65%, Validation Accuracy: 24.07%\n","Epoch 81/500, Loss: 1.4574,Train Accuracy: 41.67%, Validation Accuracy: 24.07%\n","Epoch 82/500, Loss: 1.5385,Train Accuracy: 37.04%, Validation Accuracy: 25.93%\n","Epoch 83/500, Loss: 1.4989,Train Accuracy: 39.35%, Validation Accuracy: 24.07%\n","Epoch 84/500, Loss: 1.4999,Train Accuracy: 42.59%, Validation Accuracy: 24.07%\n","Epoch 85/500, Loss: 1.5060,Train Accuracy: 38.89%, Validation Accuracy: 22.22%\n","Epoch 86/500, Loss: 1.4840,Train Accuracy: 37.96%, Validation Accuracy: 24.07%\n","Epoch 87/500, Loss: 1.4987,Train Accuracy: 38.43%, Validation Accuracy: 24.07%\n","Epoch 88/500, Loss: 1.4672,Train Accuracy: 42.59%, Validation Accuracy: 24.07%\n","Epoch 89/500, Loss: 1.4876,Train Accuracy: 43.06%, Validation Accuracy: 24.07%\n","Epoch 90/500, Loss: 1.4702,Train Accuracy: 38.43%, Validation Accuracy: 24.07%\n","Epoch 91/500, Loss: 1.5329,Train Accuracy: 34.72%, Validation Accuracy: 24.07%\n","Epoch 92/500, Loss: 1.4781,Train Accuracy: 41.20%, Validation Accuracy: 24.07%\n","Epoch 93/500, Loss: 1.5072,Train Accuracy: 37.50%, Validation Accuracy: 24.07%\n","Epoch 94/500, Loss: 1.4856,Train Accuracy: 41.20%, Validation Accuracy: 24.07%\n","Epoch 95/500, Loss: 1.4651,Train Accuracy: 43.98%, Validation Accuracy: 24.07%\n","Epoch 96/500, Loss: 1.4439,Train Accuracy: 44.44%, Validation Accuracy: 24.07%\n","Epoch 97/500, Loss: 1.4683,Train Accuracy: 45.83%, Validation Accuracy: 24.07%\n","Epoch 98/500, Loss: 1.4697,Train Accuracy: 41.20%, Validation Accuracy: 24.07%\n","Epoch 99/500, Loss: 1.4399,Train Accuracy: 45.37%, Validation Accuracy: 24.07%\n","Epoch 100/500, Loss: 1.4745,Train Accuracy: 42.59%, Validation Accuracy: 22.22%\n","Epoch 101/500, Loss: 1.4652,Train Accuracy: 40.74%, Validation Accuracy: 24.07%\n","Epoch 102/500, Loss: 1.4621,Train Accuracy: 40.28%, Validation Accuracy: 24.07%\n","Epoch 103/500, Loss: 1.4702,Train Accuracy: 43.98%, Validation Accuracy: 24.07%\n","Epoch 104/500, Loss: 1.4724,Train Accuracy: 40.74%, Validation Accuracy: 24.07%\n","Epoch 105/500, Loss: 1.4585,Train Accuracy: 43.06%, Validation Accuracy: 24.07%\n","Epoch 106/500, Loss: 1.4588,Train Accuracy: 42.13%, Validation Accuracy: 24.07%\n","Epoch 107/500, Loss: 1.4837,Train Accuracy: 38.43%, Validation Accuracy: 24.07%\n","Epoch 108/500, Loss: 1.4737,Train Accuracy: 38.89%, Validation Accuracy: 24.07%\n","Epoch 109/500, Loss: 1.4663,Train Accuracy: 42.59%, Validation Accuracy: 24.07%\n","Epoch 110/500, Loss: 1.4541,Train Accuracy: 46.76%, Validation Accuracy: 24.07%\n","Epoch 111/500, Loss: 1.4402,Train Accuracy: 49.54%, Validation Accuracy: 24.07%\n","Epoch 112/500, Loss: 1.4666,Train Accuracy: 41.20%, Validation Accuracy: 24.07%\n","Epoch 113/500, Loss: 1.4719,Train Accuracy: 46.30%, Validation Accuracy: 24.07%\n","Epoch 114/500, Loss: 1.4768,Train Accuracy: 44.91%, Validation Accuracy: 24.07%\n","Epoch 115/500, Loss: 1.4596,Train Accuracy: 43.98%, Validation Accuracy: 24.07%\n","Epoch 116/500, Loss: 1.4614,Train Accuracy: 43.52%, Validation Accuracy: 24.07%\n","Epoch 117/500, Loss: 1.4276,Train Accuracy: 44.91%, Validation Accuracy: 24.07%\n","Epoch 118/500, Loss: 1.4310,Train Accuracy: 45.83%, Validation Accuracy: 24.07%\n","Epoch 119/500, Loss: 1.4467,Train Accuracy: 40.74%, Validation Accuracy: 24.07%\n","Epoch 120/500, Loss: 1.4569,Train Accuracy: 46.30%, Validation Accuracy: 24.07%\n","Epoch 121/500, Loss: 1.4623,Train Accuracy: 46.76%, Validation Accuracy: 24.07%\n","Epoch 122/500, Loss: 1.4364,Train Accuracy: 47.69%, Validation Accuracy: 24.07%\n","Epoch 123/500, Loss: 1.4736,Train Accuracy: 39.81%, Validation Accuracy: 24.07%\n","Epoch 124/500, Loss: 1.4637,Train Accuracy: 43.98%, Validation Accuracy: 24.07%\n","Epoch 125/500, Loss: 1.4669,Train Accuracy: 41.67%, Validation Accuracy: 24.07%\n","Epoch 126/500, Loss: 1.4490,Train Accuracy: 42.13%, Validation Accuracy: 24.07%\n","Epoch 127/500, Loss: 1.4287,Train Accuracy: 47.22%, Validation Accuracy: 24.07%\n","Epoch 128/500, Loss: 1.4462,Train Accuracy: 44.44%, Validation Accuracy: 24.07%\n","Epoch 129/500, Loss: 1.4513,Train Accuracy: 49.07%, Validation Accuracy: 24.07%\n","Epoch 130/500, Loss: 1.4444,Train Accuracy: 43.98%, Validation Accuracy: 24.07%\n","Epoch 131/500, Loss: 1.4171,Train Accuracy: 47.22%, Validation Accuracy: 24.07%\n","Epoch 132/500, Loss: 1.4730,Train Accuracy: 43.06%, Validation Accuracy: 24.07%\n","Epoch 133/500, Loss: 1.4090,Train Accuracy: 49.07%, Validation Accuracy: 24.07%\n","Epoch 134/500, Loss: 1.4642,Train Accuracy: 44.91%, Validation Accuracy: 24.07%\n","Epoch 135/500, Loss: 1.4692,Train Accuracy: 44.91%, Validation Accuracy: 25.93%\n","Epoch 136/500, Loss: 1.4565,Train Accuracy: 45.37%, Validation Accuracy: 24.07%\n","Epoch 137/500, Loss: 1.4096,Train Accuracy: 51.39%, Validation Accuracy: 24.07%\n","Epoch 138/500, Loss: 1.4198,Train Accuracy: 46.76%, Validation Accuracy: 24.07%\n","Epoch 139/500, Loss: 1.4232,Train Accuracy: 48.15%, Validation Accuracy: 24.07%\n","Epoch 140/500, Loss: 1.4443,Train Accuracy: 43.98%, Validation Accuracy: 24.07%\n","Epoch 141/500, Loss: 1.4501,Train Accuracy: 44.91%, Validation Accuracy: 24.07%\n","Epoch 142/500, Loss: 1.4350,Train Accuracy: 48.15%, Validation Accuracy: 24.07%\n","Epoch 143/500, Loss: 1.4248,Train Accuracy: 48.61%, Validation Accuracy: 24.07%\n","Epoch 144/500, Loss: 1.4298,Train Accuracy: 47.69%, Validation Accuracy: 24.07%\n","Epoch 145/500, Loss: 1.4102,Train Accuracy: 47.69%, Validation Accuracy: 24.07%\n","Epoch 146/500, Loss: 1.4572,Train Accuracy: 43.98%, Validation Accuracy: 22.22%\n","Epoch 147/500, Loss: 1.4276,Train Accuracy: 48.61%, Validation Accuracy: 24.07%\n","Epoch 148/500, Loss: 1.4361,Train Accuracy: 43.06%, Validation Accuracy: 22.22%\n","Epoch 149/500, Loss: 1.4450,Train Accuracy: 42.59%, Validation Accuracy: 22.22%\n","Epoch 150/500, Loss: 1.4332,Train Accuracy: 46.76%, Validation Accuracy: 22.22%\n","Epoch 151/500, Loss: 1.4130,Train Accuracy: 48.61%, Validation Accuracy: 22.22%\n","Epoch 152/500, Loss: 1.4540,Train Accuracy: 46.30%, Validation Accuracy: 22.22%\n","Epoch 153/500, Loss: 1.4097,Train Accuracy: 49.07%, Validation Accuracy: 22.22%\n","Epoch 154/500, Loss: 1.3865,Train Accuracy: 51.39%, Validation Accuracy: 22.22%\n","Epoch 155/500, Loss: 1.4539,Train Accuracy: 47.22%, Validation Accuracy: 22.22%\n","Epoch 156/500, Loss: 1.4130,Train Accuracy: 48.15%, Validation Accuracy: 22.22%\n","Epoch 157/500, Loss: 1.4221,Train Accuracy: 50.93%, Validation Accuracy: 22.22%\n","Epoch 158/500, Loss: 1.4219,Train Accuracy: 45.37%, Validation Accuracy: 18.52%\n","Epoch 159/500, Loss: 1.4155,Train Accuracy: 48.61%, Validation Accuracy: 20.37%\n","Epoch 160/500, Loss: 1.3867,Train Accuracy: 54.17%, Validation Accuracy: 22.22%\n","Epoch 161/500, Loss: 1.4082,Train Accuracy: 48.15%, Validation Accuracy: 22.22%\n","Epoch 162/500, Loss: 1.4087,Train Accuracy: 48.15%, Validation Accuracy: 22.22%\n","Epoch 163/500, Loss: 1.3991,Train Accuracy: 50.93%, Validation Accuracy: 22.22%\n","Epoch 164/500, Loss: 1.4413,Train Accuracy: 44.91%, Validation Accuracy: 22.22%\n","Epoch 165/500, Loss: 1.3996,Train Accuracy: 50.93%, Validation Accuracy: 22.22%\n","Epoch 166/500, Loss: 1.3688,Train Accuracy: 56.94%, Validation Accuracy: 22.22%\n","Epoch 167/500, Loss: 1.4150,Train Accuracy: 50.93%, Validation Accuracy: 22.22%\n","Epoch 168/500, Loss: 1.4192,Train Accuracy: 50.46%, Validation Accuracy: 24.07%\n","Epoch 169/500, Loss: 1.3955,Train Accuracy: 54.63%, Validation Accuracy: 24.07%\n","Epoch 170/500, Loss: 1.4083,Train Accuracy: 48.61%, Validation Accuracy: 24.07%\n","Epoch 171/500, Loss: 1.3802,Train Accuracy: 51.85%, Validation Accuracy: 24.07%\n","Epoch 172/500, Loss: 1.3775,Train Accuracy: 54.63%, Validation Accuracy: 22.22%\n","Epoch 173/500, Loss: 1.4301,Train Accuracy: 48.15%, Validation Accuracy: 22.22%\n","Epoch 174/500, Loss: 1.3692,Train Accuracy: 56.48%, Validation Accuracy: 22.22%\n","Epoch 175/500, Loss: 1.3530,Train Accuracy: 57.87%, Validation Accuracy: 22.22%\n","Epoch 176/500, Loss: 1.3526,Train Accuracy: 57.41%, Validation Accuracy: 22.22%\n","Epoch 177/500, Loss: 1.4238,Train Accuracy: 49.07%, Validation Accuracy: 22.22%\n","Epoch 178/500, Loss: 1.4110,Train Accuracy: 49.54%, Validation Accuracy: 22.22%\n","Epoch 179/500, Loss: 1.3752,Train Accuracy: 52.78%, Validation Accuracy: 22.22%\n","Epoch 180/500, Loss: 1.3910,Train Accuracy: 52.78%, Validation Accuracy: 22.22%\n","Epoch 181/500, Loss: 1.3894,Train Accuracy: 50.93%, Validation Accuracy: 22.22%\n","Epoch 182/500, Loss: 1.3788,Train Accuracy: 56.02%, Validation Accuracy: 24.07%\n","Epoch 183/500, Loss: 1.3976,Train Accuracy: 49.54%, Validation Accuracy: 22.22%\n","Epoch 184/500, Loss: 1.3612,Train Accuracy: 54.63%, Validation Accuracy: 22.22%\n","Epoch 185/500, Loss: 1.3629,Train Accuracy: 54.17%, Validation Accuracy: 22.22%\n","Epoch 186/500, Loss: 1.3760,Train Accuracy: 53.70%, Validation Accuracy: 22.22%\n","Epoch 187/500, Loss: 1.3776,Train Accuracy: 52.78%, Validation Accuracy: 22.22%\n","Epoch 188/500, Loss: 1.3857,Train Accuracy: 54.17%, Validation Accuracy: 22.22%\n","Epoch 189/500, Loss: 1.3634,Train Accuracy: 55.56%, Validation Accuracy: 20.37%\n","Epoch 190/500, Loss: 1.4060,Train Accuracy: 54.63%, Validation Accuracy: 20.37%\n","Epoch 191/500, Loss: 1.3849,Train Accuracy: 54.17%, Validation Accuracy: 22.22%\n","Epoch 192/500, Loss: 1.3615,Train Accuracy: 56.94%, Validation Accuracy: 22.22%\n","Epoch 193/500, Loss: 1.3934,Train Accuracy: 47.69%, Validation Accuracy: 20.37%\n","Epoch 194/500, Loss: 1.3839,Train Accuracy: 49.54%, Validation Accuracy: 20.37%\n","Epoch 195/500, Loss: 1.3725,Train Accuracy: 56.94%, Validation Accuracy: 20.37%\n","Epoch 196/500, Loss: 1.3747,Train Accuracy: 55.09%, Validation Accuracy: 20.37%\n","Epoch 197/500, Loss: 1.3696,Train Accuracy: 56.02%, Validation Accuracy: 20.37%\n","Epoch 198/500, Loss: 1.3794,Train Accuracy: 54.17%, Validation Accuracy: 20.37%\n","Epoch 199/500, Loss: 1.3169,Train Accuracy: 61.57%, Validation Accuracy: 20.37%\n","Epoch 200/500, Loss: 1.3594,Train Accuracy: 54.63%, Validation Accuracy: 22.22%\n","Epoch 201/500, Loss: 1.3587,Train Accuracy: 52.78%, Validation Accuracy: 22.22%\n","Epoch 202/500, Loss: 1.3906,Train Accuracy: 52.31%, Validation Accuracy: 22.22%\n","Epoch 203/500, Loss: 1.3445,Train Accuracy: 58.33%, Validation Accuracy: 20.37%\n","Epoch 204/500, Loss: 1.3690,Train Accuracy: 54.63%, Validation Accuracy: 20.37%\n","Epoch 205/500, Loss: 1.3681,Train Accuracy: 53.70%, Validation Accuracy: 20.37%\n","Epoch 206/500, Loss: 1.3426,Train Accuracy: 59.26%, Validation Accuracy: 20.37%\n","Epoch 207/500, Loss: 1.3365,Train Accuracy: 59.72%, Validation Accuracy: 20.37%\n","Epoch 208/500, Loss: 1.3589,Train Accuracy: 56.94%, Validation Accuracy: 20.37%\n","Epoch 209/500, Loss: 1.3674,Train Accuracy: 56.94%, Validation Accuracy: 20.37%\n","Epoch 210/500, Loss: 1.3542,Train Accuracy: 55.09%, Validation Accuracy: 20.37%\n","Epoch 211/500, Loss: 1.3412,Train Accuracy: 60.19%, Validation Accuracy: 20.37%\n","Epoch 212/500, Loss: 1.3703,Train Accuracy: 56.48%, Validation Accuracy: 20.37%\n","Epoch 213/500, Loss: 1.3417,Train Accuracy: 58.33%, Validation Accuracy: 20.37%\n","Epoch 214/500, Loss: 1.3592,Train Accuracy: 58.80%, Validation Accuracy: 20.37%\n","Epoch 215/500, Loss: 1.3784,Train Accuracy: 56.48%, Validation Accuracy: 20.37%\n","Epoch 216/500, Loss: 1.3584,Train Accuracy: 55.09%, Validation Accuracy: 20.37%\n","Epoch 217/500, Loss: 1.3578,Train Accuracy: 53.24%, Validation Accuracy: 20.37%\n","Epoch 218/500, Loss: 1.3500,Train Accuracy: 53.24%, Validation Accuracy: 20.37%\n","Epoch 219/500, Loss: 1.3688,Train Accuracy: 54.63%, Validation Accuracy: 20.37%\n","Epoch 220/500, Loss: 1.3705,Train Accuracy: 55.09%, Validation Accuracy: 20.37%\n","Epoch 221/500, Loss: 1.3905,Train Accuracy: 53.70%, Validation Accuracy: 22.22%\n","Epoch 222/500, Loss: 1.3511,Train Accuracy: 58.80%, Validation Accuracy: 20.37%\n","Epoch 223/500, Loss: 1.3355,Train Accuracy: 58.80%, Validation Accuracy: 22.22%\n","Epoch 224/500, Loss: 1.3228,Train Accuracy: 56.02%, Validation Accuracy: 22.22%\n","Epoch 225/500, Loss: 1.3563,Train Accuracy: 55.56%, Validation Accuracy: 22.22%\n","Epoch 226/500, Loss: 1.3089,Train Accuracy: 61.11%, Validation Accuracy: 24.07%\n","Epoch 227/500, Loss: 1.3484,Train Accuracy: 58.80%, Validation Accuracy: 24.07%\n","Epoch 228/500, Loss: 1.3649,Train Accuracy: 54.17%, Validation Accuracy: 25.93%\n","Epoch 229/500, Loss: 1.3070,Train Accuracy: 56.48%, Validation Accuracy: 25.93%\n","Epoch 230/500, Loss: 1.3445,Train Accuracy: 56.94%, Validation Accuracy: 25.93%\n","Epoch 231/500, Loss: 1.3488,Train Accuracy: 53.70%, Validation Accuracy: 25.93%\n","Epoch 232/500, Loss: 1.3481,Train Accuracy: 57.41%, Validation Accuracy: 25.93%\n","Epoch 233/500, Loss: 1.3426,Train Accuracy: 57.87%, Validation Accuracy: 25.93%\n","Epoch 234/500, Loss: 1.3558,Train Accuracy: 55.09%, Validation Accuracy: 25.93%\n","Epoch 235/500, Loss: 1.3332,Train Accuracy: 60.65%, Validation Accuracy: 25.93%\n","Epoch 236/500, Loss: 1.3527,Train Accuracy: 56.94%, Validation Accuracy: 24.07%\n","Epoch 237/500, Loss: 1.3120,Train Accuracy: 58.80%, Validation Accuracy: 24.07%\n","Epoch 238/500, Loss: 1.3389,Train Accuracy: 57.87%, Validation Accuracy: 24.07%\n","Epoch 239/500, Loss: 1.3234,Train Accuracy: 58.80%, Validation Accuracy: 24.07%\n","Epoch 240/500, Loss: 1.3333,Train Accuracy: 59.26%, Validation Accuracy: 24.07%\n","Epoch 241/500, Loss: 1.3659,Train Accuracy: 58.33%, Validation Accuracy: 22.22%\n","Epoch 242/500, Loss: 1.3229,Train Accuracy: 57.41%, Validation Accuracy: 22.22%\n","Epoch 243/500, Loss: 1.3383,Train Accuracy: 62.96%, Validation Accuracy: 22.22%\n","Epoch 244/500, Loss: 1.3322,Train Accuracy: 60.65%, Validation Accuracy: 20.37%\n","Epoch 245/500, Loss: 1.3449,Train Accuracy: 55.56%, Validation Accuracy: 22.22%\n","Epoch 246/500, Loss: 1.3281,Train Accuracy: 60.65%, Validation Accuracy: 22.22%\n","Epoch 247/500, Loss: 1.3246,Train Accuracy: 62.96%, Validation Accuracy: 22.22%\n","Epoch 248/500, Loss: 1.3428,Train Accuracy: 60.19%, Validation Accuracy: 22.22%\n","Epoch 249/500, Loss: 1.3410,Train Accuracy: 55.56%, Validation Accuracy: 22.22%\n","Epoch 250/500, Loss: 1.3652,Train Accuracy: 57.87%, Validation Accuracy: 24.07%\n","Epoch 251/500, Loss: 1.3613,Train Accuracy: 52.78%, Validation Accuracy: 24.07%\n","Epoch 252/500, Loss: 1.3232,Train Accuracy: 58.33%, Validation Accuracy: 24.07%\n","Epoch 253/500, Loss: 1.3112,Train Accuracy: 61.57%, Validation Accuracy: 25.93%\n","Epoch 254/500, Loss: 1.3011,Train Accuracy: 59.72%, Validation Accuracy: 22.22%\n","Epoch 255/500, Loss: 1.3013,Train Accuracy: 62.50%, Validation Accuracy: 24.07%\n","Epoch 256/500, Loss: 1.3484,Train Accuracy: 57.87%, Validation Accuracy: 25.93%\n","Epoch 257/500, Loss: 1.3075,Train Accuracy: 64.35%, Validation Accuracy: 25.93%\n","Epoch 258/500, Loss: 1.3401,Train Accuracy: 56.48%, Validation Accuracy: 24.07%\n","Epoch 259/500, Loss: 1.3472,Train Accuracy: 58.33%, Validation Accuracy: 25.93%\n","Epoch 260/500, Loss: 1.3255,Train Accuracy: 59.26%, Validation Accuracy: 25.93%\n","Epoch 261/500, Loss: 1.2981,Train Accuracy: 65.74%, Validation Accuracy: 24.07%\n","Epoch 262/500, Loss: 1.3128,Train Accuracy: 59.26%, Validation Accuracy: 24.07%\n","Epoch 263/500, Loss: 1.3117,Train Accuracy: 60.65%, Validation Accuracy: 22.22%\n","Epoch 264/500, Loss: 1.3276,Train Accuracy: 61.57%, Validation Accuracy: 24.07%\n","Epoch 265/500, Loss: 1.3022,Train Accuracy: 62.96%, Validation Accuracy: 25.93%\n","Epoch 266/500, Loss: 1.3042,Train Accuracy: 65.28%, Validation Accuracy: 24.07%\n","Epoch 267/500, Loss: 1.3379,Train Accuracy: 57.41%, Validation Accuracy: 24.07%\n","Epoch 268/500, Loss: 1.3562,Train Accuracy: 59.26%, Validation Accuracy: 24.07%\n","Epoch 269/500, Loss: 1.3156,Train Accuracy: 61.57%, Validation Accuracy: 25.93%\n","Epoch 270/500, Loss: 1.2774,Train Accuracy: 62.96%, Validation Accuracy: 25.93%\n","Epoch 271/500, Loss: 1.3464,Train Accuracy: 57.41%, Validation Accuracy: 24.07%\n","Epoch 272/500, Loss: 1.3088,Train Accuracy: 62.50%, Validation Accuracy: 25.93%\n","Epoch 273/500, Loss: 1.2970,Train Accuracy: 61.11%, Validation Accuracy: 25.93%\n","Epoch 274/500, Loss: 1.3313,Train Accuracy: 60.19%, Validation Accuracy: 25.93%\n","Epoch 275/500, Loss: 1.3050,Train Accuracy: 59.26%, Validation Accuracy: 27.78%\n","Epoch 276/500, Loss: 1.3436,Train Accuracy: 58.33%, Validation Accuracy: 27.78%\n","Epoch 277/500, Loss: 1.3256,Train Accuracy: 58.33%, Validation Accuracy: 27.78%\n","Epoch 278/500, Loss: 1.2753,Train Accuracy: 66.20%, Validation Accuracy: 27.78%\n","Epoch 279/500, Loss: 1.3285,Train Accuracy: 58.80%, Validation Accuracy: 27.78%\n","Epoch 280/500, Loss: 1.2998,Train Accuracy: 62.04%, Validation Accuracy: 25.93%\n","Epoch 281/500, Loss: 1.3118,Train Accuracy: 61.57%, Validation Accuracy: 25.93%\n","Epoch 282/500, Loss: 1.2933,Train Accuracy: 64.35%, Validation Accuracy: 27.78%\n","Epoch 283/500, Loss: 1.3318,Train Accuracy: 60.65%, Validation Accuracy: 25.93%\n","Epoch 284/500, Loss: 1.2990,Train Accuracy: 62.50%, Validation Accuracy: 27.78%\n","Epoch 285/500, Loss: 1.2937,Train Accuracy: 63.43%, Validation Accuracy: 27.78%\n","Epoch 286/500, Loss: 1.3209,Train Accuracy: 59.26%, Validation Accuracy: 29.63%\n","Epoch 287/500, Loss: 1.3113,Train Accuracy: 61.57%, Validation Accuracy: 27.78%\n","Epoch 288/500, Loss: 1.3005,Train Accuracy: 61.11%, Validation Accuracy: 25.93%\n","Epoch 289/500, Loss: 1.3059,Train Accuracy: 62.04%, Validation Accuracy: 25.93%\n","Epoch 290/500, Loss: 1.3104,Train Accuracy: 62.50%, Validation Accuracy: 25.93%\n","Epoch 291/500, Loss: 1.2765,Train Accuracy: 65.74%, Validation Accuracy: 27.78%\n","Epoch 292/500, Loss: 1.3201,Train Accuracy: 56.48%, Validation Accuracy: 25.93%\n","Epoch 293/500, Loss: 1.2847,Train Accuracy: 65.28%, Validation Accuracy: 25.93%\n","Epoch 294/500, Loss: 1.2943,Train Accuracy: 62.04%, Validation Accuracy: 24.07%\n","Epoch 295/500, Loss: 1.2839,Train Accuracy: 64.81%, Validation Accuracy: 24.07%\n","Epoch 296/500, Loss: 1.2962,Train Accuracy: 63.43%, Validation Accuracy: 24.07%\n","Epoch 297/500, Loss: 1.3155,Train Accuracy: 63.43%, Validation Accuracy: 25.93%\n","Epoch 298/500, Loss: 1.3229,Train Accuracy: 60.65%, Validation Accuracy: 25.93%\n","Epoch 299/500, Loss: 1.3505,Train Accuracy: 56.94%, Validation Accuracy: 25.93%\n","Epoch 300/500, Loss: 1.2894,Train Accuracy: 63.89%, Validation Accuracy: 25.93%\n","Epoch 301/500, Loss: 1.2890,Train Accuracy: 63.89%, Validation Accuracy: 27.78%\n","Epoch 302/500, Loss: 1.3254,Train Accuracy: 58.80%, Validation Accuracy: 24.07%\n","Epoch 303/500, Loss: 1.2883,Train Accuracy: 64.35%, Validation Accuracy: 27.78%\n","Epoch 304/500, Loss: 1.3027,Train Accuracy: 62.96%, Validation Accuracy: 25.93%\n","Epoch 305/500, Loss: 1.2881,Train Accuracy: 62.50%, Validation Accuracy: 27.78%\n","Epoch 306/500, Loss: 1.2756,Train Accuracy: 66.20%, Validation Accuracy: 29.63%\n","Epoch 307/500, Loss: 1.2887,Train Accuracy: 63.89%, Validation Accuracy: 29.63%\n","Epoch 308/500, Loss: 1.3001,Train Accuracy: 60.65%, Validation Accuracy: 31.48%\n","Epoch 309/500, Loss: 1.2837,Train Accuracy: 62.96%, Validation Accuracy: 31.48%\n","Epoch 310/500, Loss: 1.2799,Train Accuracy: 62.96%, Validation Accuracy: 31.48%\n","Epoch 311/500, Loss: 1.3029,Train Accuracy: 63.43%, Validation Accuracy: 27.78%\n","Epoch 312/500, Loss: 1.2762,Train Accuracy: 63.89%, Validation Accuracy: 29.63%\n","Epoch 313/500, Loss: 1.2939,Train Accuracy: 62.96%, Validation Accuracy: 31.48%\n","Epoch 314/500, Loss: 1.2941,Train Accuracy: 60.19%, Validation Accuracy: 31.48%\n","Epoch 315/500, Loss: 1.3071,Train Accuracy: 62.96%, Validation Accuracy: 31.48%\n","Epoch 316/500, Loss: 1.2885,Train Accuracy: 65.74%, Validation Accuracy: 31.48%\n","Epoch 317/500, Loss: 1.2797,Train Accuracy: 63.43%, Validation Accuracy: 31.48%\n","Epoch 318/500, Loss: 1.3143,Train Accuracy: 62.04%, Validation Accuracy: 31.48%\n","Epoch 319/500, Loss: 1.3083,Train Accuracy: 63.43%, Validation Accuracy: 31.48%\n","Epoch 320/500, Loss: 1.3059,Train Accuracy: 58.80%, Validation Accuracy: 29.63%\n","Epoch 321/500, Loss: 1.3097,Train Accuracy: 61.11%, Validation Accuracy: 29.63%\n","Epoch 322/500, Loss: 1.2530,Train Accuracy: 65.74%, Validation Accuracy: 31.48%\n","Epoch 323/500, Loss: 1.3269,Train Accuracy: 58.33%, Validation Accuracy: 29.63%\n","Epoch 324/500, Loss: 1.3169,Train Accuracy: 61.57%, Validation Accuracy: 29.63%\n","Epoch 325/500, Loss: 1.2759,Train Accuracy: 63.89%, Validation Accuracy: 29.63%\n","Epoch 326/500, Loss: 1.2988,Train Accuracy: 65.74%, Validation Accuracy: 29.63%\n","Epoch 327/500, Loss: 1.2864,Train Accuracy: 62.50%, Validation Accuracy: 31.48%\n","Epoch 328/500, Loss: 1.3067,Train Accuracy: 62.96%, Validation Accuracy: 29.63%\n","Epoch 329/500, Loss: 1.2977,Train Accuracy: 62.96%, Validation Accuracy: 29.63%\n","Epoch 330/500, Loss: 1.2783,Train Accuracy: 62.04%, Validation Accuracy: 31.48%\n","Epoch 331/500, Loss: 1.2573,Train Accuracy: 68.06%, Validation Accuracy: 31.48%\n","Epoch 332/500, Loss: 1.2426,Train Accuracy: 67.59%, Validation Accuracy: 33.33%\n","Epoch 333/500, Loss: 1.2952,Train Accuracy: 64.35%, Validation Accuracy: 31.48%\n","Epoch 334/500, Loss: 1.2833,Train Accuracy: 63.43%, Validation Accuracy: 31.48%\n","Epoch 335/500, Loss: 1.2679,Train Accuracy: 67.59%, Validation Accuracy: 29.63%\n","Epoch 336/500, Loss: 1.2497,Train Accuracy: 67.59%, Validation Accuracy: 29.63%\n","Epoch 337/500, Loss: 1.2991,Train Accuracy: 63.89%, Validation Accuracy: 29.63%\n","Epoch 338/500, Loss: 1.2612,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 339/500, Loss: 1.2821,Train Accuracy: 65.28%, Validation Accuracy: 29.63%\n","Epoch 340/500, Loss: 1.2784,Train Accuracy: 64.81%, Validation Accuracy: 27.78%\n","Epoch 341/500, Loss: 1.2560,Train Accuracy: 68.52%, Validation Accuracy: 27.78%\n","Epoch 342/500, Loss: 1.2606,Train Accuracy: 65.74%, Validation Accuracy: 29.63%\n","Epoch 343/500, Loss: 1.2794,Train Accuracy: 64.81%, Validation Accuracy: 29.63%\n","Epoch 344/500, Loss: 1.2626,Train Accuracy: 65.74%, Validation Accuracy: 29.63%\n","Epoch 345/500, Loss: 1.3048,Train Accuracy: 64.35%, Validation Accuracy: 29.63%\n","Epoch 346/500, Loss: 1.2592,Train Accuracy: 66.67%, Validation Accuracy: 29.63%\n","Epoch 347/500, Loss: 1.2760,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 348/500, Loss: 1.2862,Train Accuracy: 66.20%, Validation Accuracy: 29.63%\n","Epoch 349/500, Loss: 1.2636,Train Accuracy: 66.67%, Validation Accuracy: 27.78%\n","Epoch 350/500, Loss: 1.2777,Train Accuracy: 68.98%, Validation Accuracy: 27.78%\n","Epoch 351/500, Loss: 1.2571,Train Accuracy: 66.20%, Validation Accuracy: 25.93%\n","Epoch 352/500, Loss: 1.2809,Train Accuracy: 64.81%, Validation Accuracy: 25.93%\n","Epoch 353/500, Loss: 1.2574,Train Accuracy: 62.96%, Validation Accuracy: 25.93%\n","Epoch 354/500, Loss: 1.2398,Train Accuracy: 71.30%, Validation Accuracy: 27.78%\n","Epoch 355/500, Loss: 1.2688,Train Accuracy: 64.81%, Validation Accuracy: 25.93%\n","Epoch 356/500, Loss: 1.2542,Train Accuracy: 67.59%, Validation Accuracy: 25.93%\n","Epoch 357/500, Loss: 1.2687,Train Accuracy: 68.98%, Validation Accuracy: 25.93%\n","Epoch 358/500, Loss: 1.2593,Train Accuracy: 66.20%, Validation Accuracy: 25.93%\n","Epoch 359/500, Loss: 1.2969,Train Accuracy: 62.04%, Validation Accuracy: 24.07%\n","Epoch 360/500, Loss: 1.2905,Train Accuracy: 67.13%, Validation Accuracy: 25.93%\n","Epoch 361/500, Loss: 1.2754,Train Accuracy: 67.13%, Validation Accuracy: 27.78%\n","Epoch 362/500, Loss: 1.2902,Train Accuracy: 63.89%, Validation Accuracy: 27.78%\n","Epoch 363/500, Loss: 1.2382,Train Accuracy: 69.44%, Validation Accuracy: 27.78%\n","Epoch 364/500, Loss: 1.2629,Train Accuracy: 64.81%, Validation Accuracy: 27.78%\n","Epoch 365/500, Loss: 1.2714,Train Accuracy: 68.98%, Validation Accuracy: 27.78%\n","Epoch 366/500, Loss: 1.2897,Train Accuracy: 63.43%, Validation Accuracy: 27.78%\n","Epoch 367/500, Loss: 1.2619,Train Accuracy: 67.59%, Validation Accuracy: 29.63%\n","Epoch 368/500, Loss: 1.2911,Train Accuracy: 62.04%, Validation Accuracy: 29.63%\n","Epoch 369/500, Loss: 1.2526,Train Accuracy: 68.98%, Validation Accuracy: 29.63%\n","Epoch 370/500, Loss: 1.2303,Train Accuracy: 72.69%, Validation Accuracy: 29.63%\n","Epoch 371/500, Loss: 1.2697,Train Accuracy: 62.04%, Validation Accuracy: 29.63%\n","Epoch 372/500, Loss: 1.2770,Train Accuracy: 62.96%, Validation Accuracy: 29.63%\n","Epoch 373/500, Loss: 1.2440,Train Accuracy: 66.20%, Validation Accuracy: 29.63%\n","Epoch 374/500, Loss: 1.2867,Train Accuracy: 61.57%, Validation Accuracy: 29.63%\n","Epoch 375/500, Loss: 1.2303,Train Accuracy: 70.83%, Validation Accuracy: 29.63%\n","Epoch 376/500, Loss: 1.2881,Train Accuracy: 62.96%, Validation Accuracy: 29.63%\n","Epoch 377/500, Loss: 1.2844,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 378/500, Loss: 1.2672,Train Accuracy: 67.59%, Validation Accuracy: 29.63%\n","Epoch 379/500, Loss: 1.2561,Train Accuracy: 68.52%, Validation Accuracy: 29.63%\n","Epoch 380/500, Loss: 1.2725,Train Accuracy: 65.28%, Validation Accuracy: 31.48%\n","Epoch 381/500, Loss: 1.2578,Train Accuracy: 67.59%, Validation Accuracy: 31.48%\n","Epoch 382/500, Loss: 1.2399,Train Accuracy: 69.44%, Validation Accuracy: 29.63%\n","Epoch 383/500, Loss: 1.2669,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 384/500, Loss: 1.2638,Train Accuracy: 67.13%, Validation Accuracy: 27.78%\n","Epoch 385/500, Loss: 1.2634,Train Accuracy: 67.59%, Validation Accuracy: 25.93%\n","Epoch 386/500, Loss: 1.2252,Train Accuracy: 70.83%, Validation Accuracy: 29.63%\n","Epoch 387/500, Loss: 1.2616,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 388/500, Loss: 1.2927,Train Accuracy: 60.65%, Validation Accuracy: 27.78%\n","Epoch 389/500, Loss: 1.2427,Train Accuracy: 68.06%, Validation Accuracy: 27.78%\n","Epoch 390/500, Loss: 1.2753,Train Accuracy: 68.06%, Validation Accuracy: 25.93%\n","Epoch 391/500, Loss: 1.2415,Train Accuracy: 67.59%, Validation Accuracy: 25.93%\n","Epoch 392/500, Loss: 1.2826,Train Accuracy: 63.43%, Validation Accuracy: 25.93%\n","Epoch 393/500, Loss: 1.2549,Train Accuracy: 67.13%, Validation Accuracy: 27.78%\n","Epoch 394/500, Loss: 1.2821,Train Accuracy: 65.74%, Validation Accuracy: 29.63%\n","Epoch 395/500, Loss: 1.2396,Train Accuracy: 68.98%, Validation Accuracy: 29.63%\n","Epoch 396/500, Loss: 1.2215,Train Accuracy: 70.37%, Validation Accuracy: 31.48%\n","Epoch 397/500, Loss: 1.2483,Train Accuracy: 71.76%, Validation Accuracy: 31.48%\n","Epoch 398/500, Loss: 1.2356,Train Accuracy: 68.52%, Validation Accuracy: 31.48%\n","Epoch 399/500, Loss: 1.2492,Train Accuracy: 67.59%, Validation Accuracy: 29.63%\n","Epoch 400/500, Loss: 1.2524,Train Accuracy: 67.59%, Validation Accuracy: 27.78%\n","Epoch 401/500, Loss: 1.2521,Train Accuracy: 67.59%, Validation Accuracy: 27.78%\n","Epoch 402/500, Loss: 1.2353,Train Accuracy: 68.06%, Validation Accuracy: 27.78%\n","Epoch 403/500, Loss: 1.2329,Train Accuracy: 69.44%, Validation Accuracy: 27.78%\n","Epoch 404/500, Loss: 1.2566,Train Accuracy: 65.74%, Validation Accuracy: 29.63%\n","Epoch 405/500, Loss: 1.2743,Train Accuracy: 65.28%, Validation Accuracy: 29.63%\n","Epoch 406/500, Loss: 1.2542,Train Accuracy: 66.67%, Validation Accuracy: 29.63%\n","Epoch 407/500, Loss: 1.2489,Train Accuracy: 68.06%, Validation Accuracy: 27.78%\n","Epoch 408/500, Loss: 1.2109,Train Accuracy: 70.37%, Validation Accuracy: 27.78%\n","Epoch 409/500, Loss: 1.2362,Train Accuracy: 70.83%, Validation Accuracy: 31.48%\n","Epoch 410/500, Loss: 1.2527,Train Accuracy: 67.13%, Validation Accuracy: 27.78%\n","Epoch 411/500, Loss: 1.2502,Train Accuracy: 64.35%, Validation Accuracy: 27.78%\n","Epoch 412/500, Loss: 1.2443,Train Accuracy: 71.30%, Validation Accuracy: 29.63%\n","Epoch 413/500, Loss: 1.2845,Train Accuracy: 64.81%, Validation Accuracy: 29.63%\n","Epoch 414/500, Loss: 1.2384,Train Accuracy: 68.52%, Validation Accuracy: 29.63%\n","Epoch 415/500, Loss: 1.2404,Train Accuracy: 68.06%, Validation Accuracy: 29.63%\n","Epoch 416/500, Loss: 1.2377,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 417/500, Loss: 1.2424,Train Accuracy: 69.44%, Validation Accuracy: 29.63%\n","Epoch 418/500, Loss: 1.2233,Train Accuracy: 69.91%, Validation Accuracy: 29.63%\n","Epoch 419/500, Loss: 1.2688,Train Accuracy: 67.59%, Validation Accuracy: 31.48%\n","Epoch 420/500, Loss: 1.2236,Train Accuracy: 71.76%, Validation Accuracy: 29.63%\n","Epoch 421/500, Loss: 1.2416,Train Accuracy: 69.91%, Validation Accuracy: 29.63%\n","Epoch 422/500, Loss: 1.2309,Train Accuracy: 71.30%, Validation Accuracy: 27.78%\n","Epoch 423/500, Loss: 1.2152,Train Accuracy: 71.76%, Validation Accuracy: 29.63%\n","Epoch 424/500, Loss: 1.2163,Train Accuracy: 68.98%, Validation Accuracy: 29.63%\n","Epoch 425/500, Loss: 1.2070,Train Accuracy: 69.44%, Validation Accuracy: 27.78%\n","Epoch 426/500, Loss: 1.2545,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 427/500, Loss: 1.2307,Train Accuracy: 70.83%, Validation Accuracy: 29.63%\n","Epoch 428/500, Loss: 1.2080,Train Accuracy: 75.00%, Validation Accuracy: 27.78%\n","Epoch 429/500, Loss: 1.2273,Train Accuracy: 68.06%, Validation Accuracy: 29.63%\n","Epoch 430/500, Loss: 1.2361,Train Accuracy: 69.91%, Validation Accuracy: 27.78%\n","Epoch 431/500, Loss: 1.2551,Train Accuracy: 69.91%, Validation Accuracy: 25.93%\n","Epoch 432/500, Loss: 1.1977,Train Accuracy: 74.54%, Validation Accuracy: 25.93%\n","Epoch 433/500, Loss: 1.2347,Train Accuracy: 66.67%, Validation Accuracy: 27.78%\n","Epoch 434/500, Loss: 1.2073,Train Accuracy: 69.44%, Validation Accuracy: 29.63%\n","Epoch 435/500, Loss: 1.2192,Train Accuracy: 71.76%, Validation Accuracy: 29.63%\n","Epoch 436/500, Loss: 1.2416,Train Accuracy: 70.37%, Validation Accuracy: 27.78%\n","Epoch 437/500, Loss: 1.2110,Train Accuracy: 72.22%, Validation Accuracy: 27.78%\n","Epoch 438/500, Loss: 1.2371,Train Accuracy: 68.06%, Validation Accuracy: 29.63%\n","Epoch 439/500, Loss: 1.2501,Train Accuracy: 70.37%, Validation Accuracy: 31.48%\n","Epoch 440/500, Loss: 1.2350,Train Accuracy: 69.91%, Validation Accuracy: 27.78%\n","Epoch 441/500, Loss: 1.2552,Train Accuracy: 67.13%, Validation Accuracy: 27.78%\n","Epoch 442/500, Loss: 1.2321,Train Accuracy: 71.30%, Validation Accuracy: 25.93%\n","Epoch 443/500, Loss: 1.2235,Train Accuracy: 71.76%, Validation Accuracy: 25.93%\n","Epoch 444/500, Loss: 1.2212,Train Accuracy: 69.44%, Validation Accuracy: 29.63%\n","Epoch 445/500, Loss: 1.2222,Train Accuracy: 70.83%, Validation Accuracy: 27.78%\n","Epoch 446/500, Loss: 1.2066,Train Accuracy: 71.30%, Validation Accuracy: 31.48%\n","Epoch 447/500, Loss: 1.2073,Train Accuracy: 76.39%, Validation Accuracy: 31.48%\n","Epoch 448/500, Loss: 1.2692,Train Accuracy: 64.35%, Validation Accuracy: 31.48%\n","Epoch 449/500, Loss: 1.2198,Train Accuracy: 71.76%, Validation Accuracy: 33.33%\n","Epoch 450/500, Loss: 1.2489,Train Accuracy: 63.89%, Validation Accuracy: 31.48%\n","Epoch 451/500, Loss: 1.2152,Train Accuracy: 70.83%, Validation Accuracy: 29.63%\n","Epoch 452/500, Loss: 1.2242,Train Accuracy: 70.37%, Validation Accuracy: 29.63%\n","Epoch 453/500, Loss: 1.2242,Train Accuracy: 72.69%, Validation Accuracy: 29.63%\n","Epoch 454/500, Loss: 1.2308,Train Accuracy: 72.22%, Validation Accuracy: 27.78%\n","Epoch 455/500, Loss: 1.2214,Train Accuracy: 71.30%, Validation Accuracy: 27.78%\n","Epoch 456/500, Loss: 1.2359,Train Accuracy: 70.37%, Validation Accuracy: 27.78%\n","Epoch 457/500, Loss: 1.2076,Train Accuracy: 70.83%, Validation Accuracy: 27.78%\n","Epoch 458/500, Loss: 1.2508,Train Accuracy: 69.91%, Validation Accuracy: 27.78%\n","Epoch 459/500, Loss: 1.2164,Train Accuracy: 70.37%, Validation Accuracy: 29.63%\n","Epoch 460/500, Loss: 1.2362,Train Accuracy: 70.37%, Validation Accuracy: 29.63%\n","Epoch 461/500, Loss: 1.2345,Train Accuracy: 67.13%, Validation Accuracy: 29.63%\n","Epoch 462/500, Loss: 1.2029,Train Accuracy: 71.76%, Validation Accuracy: 29.63%\n","Epoch 463/500, Loss: 1.2185,Train Accuracy: 69.44%, Validation Accuracy: 29.63%\n","Epoch 464/500, Loss: 1.2395,Train Accuracy: 66.20%, Validation Accuracy: 29.63%\n","Epoch 465/500, Loss: 1.2131,Train Accuracy: 74.07%, Validation Accuracy: 29.63%\n","Epoch 466/500, Loss: 1.2297,Train Accuracy: 68.98%, Validation Accuracy: 27.78%\n","Epoch 467/500, Loss: 1.2458,Train Accuracy: 67.59%, Validation Accuracy: 31.48%\n","Epoch 468/500, Loss: 1.2188,Train Accuracy: 70.83%, Validation Accuracy: 31.48%\n","Epoch 469/500, Loss: 1.2104,Train Accuracy: 71.76%, Validation Accuracy: 31.48%\n","Epoch 470/500, Loss: 1.2374,Train Accuracy: 71.30%, Validation Accuracy: 29.63%\n","Epoch 471/500, Loss: 1.2162,Train Accuracy: 72.69%, Validation Accuracy: 29.63%\n","Epoch 472/500, Loss: 1.2014,Train Accuracy: 75.46%, Validation Accuracy: 29.63%\n","Epoch 473/500, Loss: 1.2100,Train Accuracy: 73.15%, Validation Accuracy: 29.63%\n","Epoch 474/500, Loss: 1.1912,Train Accuracy: 73.15%, Validation Accuracy: 29.63%\n","Epoch 475/500, Loss: 1.2164,Train Accuracy: 70.83%, Validation Accuracy: 27.78%\n","Epoch 476/500, Loss: 1.2275,Train Accuracy: 70.83%, Validation Accuracy: 25.93%\n","Epoch 477/500, Loss: 1.2017,Train Accuracy: 72.69%, Validation Accuracy: 25.93%\n","Epoch 478/500, Loss: 1.2292,Train Accuracy: 72.22%, Validation Accuracy: 25.93%\n","Epoch 479/500, Loss: 1.2200,Train Accuracy: 70.37%, Validation Accuracy: 27.78%\n","Epoch 480/500, Loss: 1.1856,Train Accuracy: 74.54%, Validation Accuracy: 27.78%\n","Epoch 481/500, Loss: 1.2163,Train Accuracy: 72.69%, Validation Accuracy: 29.63%\n","Epoch 482/500, Loss: 1.1907,Train Accuracy: 75.46%, Validation Accuracy: 29.63%\n","Epoch 483/500, Loss: 1.2319,Train Accuracy: 68.98%, Validation Accuracy: 29.63%\n","Epoch 484/500, Loss: 1.1890,Train Accuracy: 78.24%, Validation Accuracy: 29.63%\n","Epoch 485/500, Loss: 1.1809,Train Accuracy: 75.46%, Validation Accuracy: 27.78%\n","Epoch 486/500, Loss: 1.2325,Train Accuracy: 67.59%, Validation Accuracy: 27.78%\n","Epoch 487/500, Loss: 1.2114,Train Accuracy: 72.69%, Validation Accuracy: 27.78%\n","Epoch 488/500, Loss: 1.2106,Train Accuracy: 70.83%, Validation Accuracy: 29.63%\n","Epoch 489/500, Loss: 1.2317,Train Accuracy: 71.76%, Validation Accuracy: 29.63%\n","Epoch 490/500, Loss: 1.2353,Train Accuracy: 69.91%, Validation Accuracy: 29.63%\n","Epoch 491/500, Loss: 1.1753,Train Accuracy: 75.93%, Validation Accuracy: 29.63%\n","Epoch 492/500, Loss: 1.2015,Train Accuracy: 73.15%, Validation Accuracy: 27.78%\n","Epoch 493/500, Loss: 1.1883,Train Accuracy: 76.39%, Validation Accuracy: 27.78%\n","Epoch 494/500, Loss: 1.2060,Train Accuracy: 75.00%, Validation Accuracy: 27.78%\n","Epoch 495/500, Loss: 1.2207,Train Accuracy: 69.91%, Validation Accuracy: 31.48%\n","Epoch 496/500, Loss: 1.2271,Train Accuracy: 69.44%, Validation Accuracy: 27.78%\n","Epoch 497/500, Loss: 1.2053,Train Accuracy: 72.69%, Validation Accuracy: 29.63%\n","Epoch 498/500, Loss: 1.2090,Train Accuracy: 70.83%, Validation Accuracy: 31.48%\n","Epoch 499/500, Loss: 1.2089,Train Accuracy: 71.30%, Validation Accuracy: 31.48%\n","Epoch 500/500, Loss: 1.1999,Train Accuracy: 74.54%, Validation Accuracy: 31.48%\n"]}],"source":["\n","# Convert resampled data and labels to tensors\n","batch_size = 16\n","all_axes_data = np.stack((data_magnet['x'], data_magnet['y'], data_magnet['z'], data_acc['x'], data_acc['y'], data_acc['z']), axis=-1)\n","X = torch.tensor(all_axes_data, dtype=torch.float32)\n","y = torch.tensor(path_indexs, dtype=torch.long)\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2, random_state=42)\n","\n","# Create DataLoader objects for efficient batching\n","train_dataset = TensorDataset(X_train, y_train)\n","val_dataset = TensorDataset(X_val, y_val)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Set the input size, hidden size, and number of classes\n","input_size = X_train.shape[1]\n","num_classes = len(torch.unique(labels))\n","num_sensors = 6\n","# Instantiate the model, loss function, and optimizer\n","model = MLP(input_size, num_sensors, num_classes)\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.Adam(model.parameters(), lr=1e-06)\n","optimizer = optim.Adam(model.parameters(), lr=5e-07)\n","# Set seed to make result reproducible\n","torch.manual_seed(0)\n","\n","# Train the model\n","num_epochs = 500\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","for epoch in range(num_epochs):\n","    train_loss = 0.0\n","    model.train()\n","    correct_train = 0\n","    total_train = 0\n","    for i, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Forward pass\n","        \n","        outputs = model(inputs)\n","        # Compute the number of correct predictions and the total number of predictions\n","        _, predicted = torch.max(outputs.data, 1)\n","        total_train += targets.size(0)\n","        correct_train += (predicted == targets).sum().item()\n","        loss = criterion(outputs, targets)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item() * inputs.size(0)\n","    \n","    train_loss = train_loss / len(train_loader.dataset)\n","    train_accuracy = 100 * correct_train / total_train\n","\n","    # Evaluate on validation set\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","    val_accuracy = 100 * correct / total\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f},Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {val_accuracy:.2f}%\")\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Following blocks are for LSTM model for accelerometer data and magnatometer data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","class LSTM(torch.nn.Module):\n","    \"\"\"\n","    Simple RNN with LSTM cells and linear projection head.\n","    \"\"\"\n","    def __init__(self, batch_size, input_size, hidden_size, num_layers, output_size, device):\n","        \"\"\"\n","        Constructor for RNN_LSTM.\n","        :param hidden_size: The number of units for each LSTM cell.\n","        :param num_layers: The number of LSTM cells we want to use.\n","        :param input_size: The size of the text vocabulary.\n","        :param device: The device we are using to run the model.\n","        \"\"\"   \n","        super(LSTM, self).__init__()\n","        # LSTM module\n","        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers)\n","        # Fully connected layer - The output tensor of the lstm has shape [seq_len, batch, hidden_size],\n","        # i.e. it contains the outputs of the last cell for every time step.\n","        # We want to map the output back to the \"vocabulary space\", so we add a linear layer.\n","        # Importantly, the linear layer should share its parameters across time steps.\n","        # This is the case in PyTorch where the linear layer is only applied to the last dimenesion.\n","        self.fc = torch.nn.Linear(hidden_size, output_size)\n","        # Sigmoid layer\n","        self.sigmoid = torch.nn.Sigmoid()\n","        # Embedding layer TODO: (no need for embedding here?)\n","        # self.embedding = torch.nn.Embedding(input_size, input_size)\n","        # self.embedding.weight.data = torch.eye(input_size)\n","\n","        # Variables \n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.device = device\n","        # Set initial cell and hidden states to zero\n","        self.reset_hidden_state(batch_size)\n","\n","    def reset_hidden_state(self, batch_size):\n","        \"\"\"\n","        Reset initial cell and hidden states to zero. The batch size might be different during training\n","        and inference. The parameter allows to modify it consequently. \n","        :param batch_size: batch size used on the model.\n","        \"\"\"\n","        self.h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n","        self.c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Compute the forward pass of the network.\n","        :param x: The input tensor of size (batch, seq_len).\n","        :return: The activated output of the network. \n","        \"\"\"\n","        # x = self.one_hot(x) # (batch, seq_len, input_size)\n","        x = x.transpose(0, 1) # (seq_len, batch, input_size)\n","        x, (self.h_0, self.c_0) = self.lstm(x, (self.h_0, self.c_0)) #  (seq_len, batch, hidden_size)\n","        x = self.fc(x)  #  (seq_len, batch_size, output_size)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train(data_loader, device, n_epochs, use_features=False):\n","    \"\"\"\n","    Train model for n_epochs.\n","    \"\"\"\n","    \n","    model.train()\n","    for epoch in range(n_epochs):    \n","        total_loss, total_accuracy = 0., 0.\n","        for i, (x1, x2, y) in enumerate(data_loader):\n","            # x = x2\n","            x = torch.cat((x1, x2), dim=2)\n","            x = x.to(device)\n","            y = y.to(device)\n","            \n","            optimizer.zero_grad()   # zero the parameter gradients   \n","            model.reset_hidden_state(batch_size)    # reset the hidden states as we are training on a new sequence\n","            y_hat = model(x)[-1, :, :]   # forward pass\n","            loss = cross_entropy_loss(y_hat, y)  # compute loss\n","            loss.backward() # backward pass\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)  # clip the gradient to prevent exploding gradient\n","            optimizer.step()    # perform update \n","            total_loss += loss.item()\n","            total_accuracy += (torch.argmax(y_hat, dim=1) == y).float().sum()\n","\n","        total_loss /= len(data_loader)\n","        total_accuracy /= len(data_loader)*batch_size\n","        print(f\"[Epoch {epoch}] - Training : accuracy = {total_accuracy}, loss = {total_loss}\")\n","    return total_loss, total_accuracy.item()\n","\n","def val(data_loader, device, use_features=False):\n","    model.eval()\n","    with torch.no_grad():\n","        right_cases = 0\n","        all_cases = 0\n","        \n","        for i, (x1, x2, y) in enumerate(data_loader):\n","            # x = x2\n","            x = torch.cat((x1, x2), dim=2)\n","            x = x.to(device)\n","            y = y.to(device)\n","            model.reset_hidden_state(batch_size)\n","            y_hat = model(x)[-1, :, :]\n","            right_cases += np.sum((torch.argmax(y_hat, dim=1) == y).cpu().numpy())\n","            all_cases += batch_size\n","    accuracy = right_cases / all_cases\n","    print(f\"validation accuracy = {accuracy}\")\n","    return accuracy\n","\n","def train_val_save(train_data_loader, val_data_loader, device, n_epochs, partition_epoch, use_features=False):\n","    global model\n","    loop_num = int(n_epochs / partition_epoch)\n","    epochs = 0\n","    max_val_accuracy = 0\n","    train_loss_list, train_accuracy_list, validation_accuracy_list = [], [], []\n","    for _ in range(loop_num):\n","        train_loss, train_acc = train(train_data_loader, device, partition_epoch, use_features)\n","        train_loss_list += [train_loss]\n","        train_accuracy_list += [train_acc]\n","        epochs += partition_epoch\n","        accuracy = val(val_data_loader, device, use_features)\n","        validation_accuracy_list += [accuracy]\n","        if accuracy > max_val_accuracy:\n","            max_val_accuracy = accuracy\n","            print(f\"\\nAt epoch {epochs}, max validation accuracy is updated to {accuracy}, model is saved.\\n\")\n","            model = model.to(\"cpu\")\n","            torch.save(model, 'LSTM.pt')\n","            model = model.to(\"cuda\")\n","\n","    return train_loss_list, train_accuracy_list, validation_accuracy_list\n","\n","\n","if __name__ == '__main__':\n","    hidden_size = 256\n","    num_layers = 2\n","    batch_size = 16\n","    output_size = 36\n","\n","    # Select device on which we will train our model \n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(f'Using device: {device}')\n","\n","    # Convert resampled data and labels to tensors\n","    batch_size = 16\n","    all_axes_data = np.stack((data_magnet['x'], data_magnet['y'], data_magnet['z'], data_acc['x'], data_acc['y'], data_acc['z']), axis=-1)\n","    X = torch.tensor(all_axes_data, dtype=torch.float32)\n","    y = torch.tensor(path_indexs, dtype=torch.long)\n","    # Split the data into training and validation sets\n","    X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2, random_state=42)\n","\n","    # Create DataLoader objects for efficient batching\n","    train_dataset = TensorDataset(X_train, y_train)\n","    val_dataset = TensorDataset(X_val, y_val)\n","\n","    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    seq_length = train_dataset[0][0].shape[0]\n","\n","    if train_dataset.use_features:\n","        input_size = train_dataset[0][0].shape[1]\n","    else:\n","        # input_size = train_dataset[0][1].shape[1]\n","        input_size = train_dataset[0][0].shape[1] + train_dataset[0][1].shape[1]\n","    print(f'\\nSequence length: {seq_length}. Input size: {input_size}\\n')\n","\n","    # build the model\n","    model = LSTM(batch_size, input_size, hidden_size, num_layers, output_size, device)\n","    model = model.to(device)\n","    cross_entropy_loss = torch.nn.CrossEntropyLoss()\n","\n","    # count total number of parameters including non trainable\n","    total_params_count = sum(p.numel() for p in model.parameters())\n","    # count total trainable parameters\n","    trainable_params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    print(f\"Total number of trainable parameters: {total_params_count}\")\n","    print(f\"Number of trainable parameters: {trainable_params_count}\")\n","\n","    # Optimization algorithm : Adam \n","    learning_rate = 1e-4\n","    # weight_decay = 1e-5\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    train_loss_list, train_accuracy_list, validation_accuracy_list = train_val_save(train_data_loader, val_data_loader, device, 150, 1, train_dataset.use_features)\n","\n","    # save model on CPU \n","    # model = model.to(\"cpu\")\n","\n","    # Save the model, the optimizer state and current number of epochs\n","    # torch.save(model, 'LSTM.pt')\n","    plt.plot(train_loss_list, label = \"Train loss\")\n","    plt.plot(train_accuracy_list, label = \"Train acc\")\n","    plt.plot(validation_accuracy_list, label = \"Validation acc\")\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.title('Loss vs Epoch')\n","    plt.legend()\n","    plt.savefig('lstm_loss.png')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
